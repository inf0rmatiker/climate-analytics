{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eb2498ec",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-24T17:36:49.808776Z",
     "start_time": "2021-09-24T17:36:47.078490Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.7.0\n",
      "Num GPUs Available:  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-29 12:48:09.449474: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-29 12:48:09.469220: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-29 12:48:09.470336: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1'\n",
    "\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "print(tf. __version__) \n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9a3d43a",
   "metadata": {},
   "source": [
    "## Processing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "71f0bf96",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features_and_target(csv_file):\n",
    "    df = pd.read_csv(f'../spark_output/colorado/{csv_file}')\n",
    "    df.drop(['year_month_day'], axis=1, inplace=True)\n",
    "\n",
    "    features = df.iloc[:, 1:-1].values\n",
    "    target = df.iloc[:, 0].values.reshape(-1,1)\n",
    "\n",
    "    assert features.shape[0] == target.shape[0]\n",
    "    assert target.shape[1] == 1\n",
    "\n",
    "    return features, target\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f78dd08c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_train_test_val(x_values, y_values):\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x_values, y_values, test_size=0.20, random_state=42)\n",
    "\n",
    "    # 0.25 x 0.8 = 0.2\n",
    "    x_train, x_validate, y_train, y_validate = train_test_split(x_train, y_train, test_size=0.25, random_state=42)\n",
    "\n",
    "    assert x_train.shape[0] == y_train.shape[0]\n",
    "    assert x_test.shape[0] == y_test.shape[0]\n",
    "    assert x_validate.shape[0] == y_validate.shape[0]\n",
    "\n",
    "    return [x_train, x_test, x_validate], [y_train, y_test, y_validate]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8f1ccbe",
   "metadata": {},
   "source": [
    "## Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3e3bab22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_build(layers, input_shape, dropout):    \n",
    "\n",
    "    model_layers = [tf.keras.layers.Dense(layers[0], activation='relu', input_shape=input_shape)]\n",
    "    \n",
    "    for curr_layer in layers[1:]:\n",
    "        model_layers.append(tf.keras.layers.Dense(curr_layer, activation='relu'))\n",
    "        if dropout:\n",
    "            model_layers.append(tf.keras.layers.Dropout(0.2))\n",
    "\n",
    "\n",
    "    model_layers.append(tf.keras.layers.Dense(1))\n",
    "\n",
    "    return tf.keras.models.Sequential(model_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "1ec0565e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_deep_learning(county, hidden_layers, learning_rate=0.01, epochs=1000, batch_size=256, dropout=False):\n",
    " \n",
    "    features, target = get_features_and_target(county)\n",
    "\n",
    "    X, Y = split_train_test_val(features, target)\n",
    "    x_train, x_test, x_validate = X\n",
    "    y_train, y_test, y_validate = Y\n",
    "    \n",
    "    input_shape = tuple([x_train.shape[1]], )\n",
    "    loss_function = 'mae'\n",
    "    metric_type = ['mae']\n",
    "\n",
    "\n",
    "    model = model_build(hidden_layers, input_shape=input_shape ,dropout=dropout)\n",
    "    model.summary()\n",
    "    model.compile(optimizer=tf.optimizers.Adam(learning_rate=learning_rate), loss=loss_function, metrics=metric_type)\n",
    "    \n",
    "    history = model.fit(x_train, y_train, epochs=epochs, batch_size=batch_size, validation_data=(x_validate, y_validate))\n",
    "\n",
    "    model.evaluate(x_test, y_test)\n",
    "    \n",
    "    return history, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "add4a3bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "gunnison = \"G0800510.csv\"\n",
    "fremont = \"G0800430.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "63421783",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_16\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_64 (Dense)            (None, 100)               300       \n",
      "                                                                 \n",
      " dense_65 (Dense)            (None, 1)                 101       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 401\n",
      "Trainable params: 401\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/1000\n",
      "1/1 [==============================] - 1s 577ms/step - loss: 97.9517 - mae: 97.9517 - val_loss: 44.3242 - val_mae: 44.3242\n",
      "Epoch 2/1000\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 46.7369 - mae: 46.7369 - val_loss: 45.0166 - val_mae: 45.0166\n",
      "Epoch 3/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 42.3666 - mae: 42.3666 - val_loss: 54.4995 - val_mae: 54.4995\n",
      "Epoch 4/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 50.8890 - mae: 50.8890 - val_loss: 61.7086 - val_mae: 61.7086\n",
      "Epoch 5/1000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 58.8510 - mae: 58.8510 - val_loss: 66.2095 - val_mae: 66.2095\n",
      "Epoch 6/1000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 63.6052 - mae: 63.6052 - val_loss: 60.0512 - val_mae: 60.0512\n",
      "Epoch 7/1000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 56.8307 - mae: 56.8307 - val_loss: 55.0322 - val_mae: 55.0322\n",
      "Epoch 8/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 51.4189 - mae: 51.4189 - val_loss: 49.8967 - val_mae: 49.8967\n",
      "Epoch 9/1000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 46.7904 - mae: 46.7904 - val_loss: 45.7833 - val_mae: 45.7833\n",
      "Epoch 10/1000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 43.0012 - mae: 43.0012 - val_loss: 42.2974 - val_mae: 42.2974\n",
      "Epoch 11/1000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 40.9730 - mae: 40.9730 - val_loss: 39.4472 - val_mae: 39.4472\n",
      "Epoch 12/1000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 39.9467 - mae: 39.9467 - val_loss: 38.7108 - val_mae: 38.7108\n",
      "Epoch 13/1000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 40.3722 - mae: 40.3722 - val_loss: 44.6360 - val_mae: 44.6360\n",
      "Epoch 14/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 47.0537 - mae: 47.0537 - val_loss: 44.8311 - val_mae: 44.8311\n",
      "Epoch 15/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 47.2485 - mae: 47.2485 - val_loss: 39.1097 - val_mae: 39.1097\n",
      "Epoch 16/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 41.1590 - mae: 41.1590 - val_loss: 38.7395 - val_mae: 38.7395\n",
      "Epoch 17/1000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 40.0746 - mae: 40.0746 - val_loss: 39.6717 - val_mae: 39.6717\n",
      "Epoch 18/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 39.9849 - mae: 39.9849 - val_loss: 41.0809 - val_mae: 41.0809\n",
      "Epoch 19/1000\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 40.3472 - mae: 40.3472 - val_loss: 42.2059 - val_mae: 42.2059\n",
      "Epoch 20/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 40.9410 - mae: 40.9410 - val_loss: 43.1956 - val_mae: 43.1956\n",
      "Epoch 21/1000\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 41.4190 - mae: 41.4190 - val_loss: 43.9152 - val_mae: 43.9152\n",
      "Epoch 22/1000\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 41.7619 - mae: 41.7619 - val_loss: 44.3823 - val_mae: 44.3823\n",
      "Epoch 23/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 41.9840 - mae: 41.9840 - val_loss: 44.6183 - val_mae: 44.6183\n",
      "Epoch 24/1000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 42.1282 - mae: 42.1282 - val_loss: 44.5772 - val_mae: 44.5772\n",
      "Epoch 25/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 42.0995 - mae: 42.0995 - val_loss: 44.2765 - val_mae: 44.2765\n",
      "Epoch 26/1000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 41.9291 - mae: 41.9291 - val_loss: 43.8184 - val_mae: 43.8184\n",
      "Epoch 27/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 41.7085 - mae: 41.7085 - val_loss: 43.2230 - val_mae: 43.2230\n",
      "Epoch 28/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 41.4222 - mae: 41.4222 - val_loss: 42.4959 - val_mae: 42.4959\n",
      "Epoch 29/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 41.0728 - mae: 41.0728 - val_loss: 41.7391 - val_mae: 41.7391\n",
      "Epoch 30/1000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 40.6675 - mae: 40.6675 - val_loss: 40.9313 - val_mae: 40.9313\n",
      "Epoch 31/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 40.2551 - mae: 40.2551 - val_loss: 40.0587 - val_mae: 40.0587\n",
      "Epoch 32/1000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 39.9963 - mae: 39.9963 - val_loss: 39.2599 - val_mae: 39.2599\n",
      "Epoch 33/1000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 39.9398 - mae: 39.9398 - val_loss: 38.7615 - val_mae: 38.7615\n",
      "Epoch 34/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 39.9634 - mae: 39.9634 - val_loss: 38.6570 - val_mae: 38.6570\n",
      "Epoch 35/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 40.0621 - mae: 40.0621 - val_loss: 38.6039 - val_mae: 38.6039\n",
      "Epoch 36/1000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 40.2052 - mae: 40.2052 - val_loss: 38.6569 - val_mae: 38.6569\n",
      "Epoch 37/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 40.3236 - mae: 40.3236 - val_loss: 38.7137 - val_mae: 38.7137\n",
      "Epoch 38/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 40.4698 - mae: 40.4698 - val_loss: 38.6511 - val_mae: 38.6511\n",
      "Epoch 39/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 40.3285 - mae: 40.3285 - val_loss: 38.5817 - val_mae: 38.5817\n",
      "Epoch 40/1000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 40.2053 - mae: 40.2053 - val_loss: 38.5949 - val_mae: 38.5949\n",
      "Epoch 41/1000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 40.0773 - mae: 40.0773 - val_loss: 38.6462 - val_mae: 38.6462\n",
      "Epoch 42/1000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 39.9664 - mae: 39.9664 - val_loss: 38.7247 - val_mae: 38.7247\n",
      "Epoch 43/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 39.9041 - mae: 39.9041 - val_loss: 39.0025 - val_mae: 39.0025\n",
      "Epoch 44/1000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 39.8785 - mae: 39.8785 - val_loss: 39.3218 - val_mae: 39.3218\n",
      "Epoch 45/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 39.8596 - mae: 39.8596 - val_loss: 39.6931 - val_mae: 39.6931\n",
      "Epoch 46/1000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 39.8700 - mae: 39.8700 - val_loss: 40.0094 - val_mae: 40.0094\n",
      "Epoch 47/1000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 39.9102 - mae: 39.9102 - val_loss: 40.2504 - val_mae: 40.2504\n",
      "Epoch 48/1000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 39.9459 - mae: 39.9459 - val_loss: 40.3921 - val_mae: 40.3921\n",
      "Epoch 49/1000\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 39.9781 - mae: 39.9781 - val_loss: 40.4163 - val_mae: 40.4163\n",
      "Epoch 50/1000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 39.9809 - mae: 39.9809 - val_loss: 40.3260 - val_mae: 40.3260\n",
      "Epoch 51/1000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 39.9463 - mae: 39.9463 - val_loss: 40.1357 - val_mae: 40.1357\n",
      "Epoch 52/1000\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 39.8970 - mae: 39.8970 - val_loss: 39.8883 - val_mae: 39.8883\n",
      "Epoch 53/1000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 39.8518 - mae: 39.8518 - val_loss: 39.6149 - val_mae: 39.6149\n",
      "Epoch 54/1000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 39.8044 - mae: 39.8044 - val_loss: 39.3287 - val_mae: 39.3287\n",
      "Epoch 55/1000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 39.7750 - mae: 39.7750 - val_loss: 39.1158 - val_mae: 39.1158\n",
      "Epoch 56/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 39.7727 - mae: 39.7727 - val_loss: 38.9345 - val_mae: 38.9345\n",
      "Epoch 57/1000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 39.7693 - mae: 39.7693 - val_loss: 38.8083 - val_mae: 38.8083\n",
      "Epoch 58/1000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 39.7652 - mae: 39.7652 - val_loss: 38.6993 - val_mae: 38.6993\n",
      "Epoch 59/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 39.7599 - mae: 39.7599 - val_loss: 38.6070 - val_mae: 38.6070\n",
      "Epoch 60/1000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 39.7599 - mae: 39.7599 - val_loss: 38.5691 - val_mae: 38.5691\n",
      "Epoch 61/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 39.7574 - mae: 39.7574 - val_loss: 38.5454 - val_mae: 38.5454\n",
      "Epoch 62/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 39.7518 - mae: 39.7518 - val_loss: 38.5334 - val_mae: 38.5334\n",
      "Epoch 63/1000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 39.7427 - mae: 39.7427 - val_loss: 38.5311 - val_mae: 38.5311\n",
      "Epoch 64/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 39.7308 - mae: 39.7308 - val_loss: 38.5396 - val_mae: 38.5396\n",
      "Epoch 65/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 39.7156 - mae: 39.7156 - val_loss: 38.5631 - val_mae: 38.5631\n",
      "Epoch 66/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 39.6985 - mae: 39.6985 - val_loss: 38.6257 - val_mae: 38.6257\n",
      "Epoch 67/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 39.6793 - mae: 39.6793 - val_loss: 38.6897 - val_mae: 38.6897\n",
      "Epoch 68/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 39.6655 - mae: 39.6655 - val_loss: 38.7529 - val_mae: 38.7529\n",
      "Epoch 69/1000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 39.6516 - mae: 39.6516 - val_loss: 38.8185 - val_mae: 38.8185\n",
      "Epoch 70/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 39.6375 - mae: 39.6375 - val_loss: 38.9044 - val_mae: 38.9044\n",
      "Epoch 71/1000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 39.6232 - mae: 39.6232 - val_loss: 38.9935 - val_mae: 38.9935\n",
      "Epoch 72/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 39.6088 - mae: 39.6088 - val_loss: 39.0765 - val_mae: 39.0765\n",
      "Epoch 73/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 39.5941 - mae: 39.5941 - val_loss: 39.1756 - val_mae: 39.1756\n",
      "Epoch 74/1000\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 39.5862 - mae: 39.5862 - val_loss: 39.2613 - val_mae: 39.2613\n",
      "Epoch 75/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 39.5809 - mae: 39.5809 - val_loss: 39.3005 - val_mae: 39.3005\n",
      "Epoch 76/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 39.5740 - mae: 39.5740 - val_loss: 39.2914 - val_mae: 39.2914\n",
      "Epoch 77/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 39.5627 - mae: 39.5627 - val_loss: 39.2424 - val_mae: 39.2424\n",
      "Epoch 78/1000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 39.5477 - mae: 39.5477 - val_loss: 39.1601 - val_mae: 39.1601\n",
      "Epoch 79/1000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 39.5302 - mae: 39.5302 - val_loss: 39.0674 - val_mae: 39.0674\n",
      "Epoch 80/1000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 39.5159 - mae: 39.5159 - val_loss: 38.9743 - val_mae: 38.9743\n",
      "Epoch 81/1000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 39.5013 - mae: 39.5013 - val_loss: 38.8853 - val_mae: 38.8853\n",
      "Epoch 82/1000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 39.4902 - mae: 39.4902 - val_loss: 38.8149 - val_mae: 38.8149\n",
      "Epoch 83/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 39.4797 - mae: 39.4797 - val_loss: 38.7575 - val_mae: 38.7575\n",
      "Epoch 84/1000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 39.4688 - mae: 39.4688 - val_loss: 38.7153 - val_mae: 38.7153\n",
      "Epoch 85/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 39.4569 - mae: 39.4569 - val_loss: 38.6888 - val_mae: 38.6888\n",
      "Epoch 86/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 39.4446 - mae: 39.4446 - val_loss: 38.6760 - val_mae: 38.6760\n",
      "Epoch 87/1000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 39.4316 - mae: 39.4316 - val_loss: 38.6703 - val_mae: 38.6703\n",
      "Epoch 88/1000\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 39.4181 - mae: 39.4181 - val_loss: 38.6755 - val_mae: 38.6755\n",
      "Epoch 89/1000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 39.4040 - mae: 39.4040 - val_loss: 38.6914 - val_mae: 38.6914\n",
      "Epoch 90/1000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 39.3898 - mae: 39.3898 - val_loss: 38.7180 - val_mae: 38.7180\n",
      "Epoch 91/1000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 39.3748 - mae: 39.3748 - val_loss: 38.7515 - val_mae: 38.7515\n",
      "Epoch 92/1000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 39.3596 - mae: 39.3596 - val_loss: 38.7926 - val_mae: 38.7926\n",
      "Epoch 93/1000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 39.3472 - mae: 39.3472 - val_loss: 38.8164 - val_mae: 38.8164\n",
      "Epoch 94/1000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 39.3350 - mae: 39.3350 - val_loss: 38.8224 - val_mae: 38.8224\n",
      "Epoch 95/1000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 39.3221 - mae: 39.3221 - val_loss: 38.8128 - val_mae: 38.8128\n",
      "Epoch 96/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 39.3085 - mae: 39.3085 - val_loss: 38.7877 - val_mae: 38.7877\n",
      "Epoch 97/1000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 39.2941 - mae: 39.2941 - val_loss: 38.7457 - val_mae: 38.7457\n",
      "Epoch 98/1000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 39.2790 - mae: 39.2790 - val_loss: 38.6985 - val_mae: 38.6985\n",
      "Epoch 99/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 39.2636 - mae: 39.2636 - val_loss: 38.6332 - val_mae: 38.6332\n",
      "Epoch 100/1000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 39.2473 - mae: 39.2473 - val_loss: 38.5581 - val_mae: 38.5581\n",
      "Epoch 101/1000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 39.2330 - mae: 39.2330 - val_loss: 38.5090 - val_mae: 38.5090\n",
      "Epoch 102/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 39.2193 - mae: 39.2193 - val_loss: 38.4697 - val_mae: 38.4697\n",
      "Epoch 103/1000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 39.2050 - mae: 39.2050 - val_loss: 38.4460 - val_mae: 38.4460\n",
      "Epoch 104/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 39.1900 - mae: 39.1900 - val_loss: 38.4373 - val_mae: 38.4373\n",
      "Epoch 105/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 39.1744 - mae: 39.1744 - val_loss: 38.4398 - val_mae: 38.4398\n",
      "Epoch 106/1000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 39.1582 - mae: 39.1582 - val_loss: 38.4583 - val_mae: 38.4583\n",
      "Epoch 107/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 39.1414 - mae: 39.1414 - val_loss: 38.4857 - val_mae: 38.4857\n",
      "Epoch 108/1000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 39.1266 - mae: 39.1266 - val_loss: 38.4915 - val_mae: 38.4915\n",
      "Epoch 109/1000\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 39.1116 - mae: 39.1116 - val_loss: 38.4832 - val_mae: 38.4832\n",
      "Epoch 110/1000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 39.0963 - mae: 39.0963 - val_loss: 38.4553 - val_mae: 38.4553\n",
      "Epoch 111/1000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 39.0799 - mae: 39.0799 - val_loss: 38.4081 - val_mae: 38.4081\n",
      "Epoch 112/1000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 39.0626 - mae: 39.0626 - val_loss: 38.3516 - val_mae: 38.3516\n",
      "Epoch 113/1000\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 39.0450 - mae: 39.0450 - val_loss: 38.2793 - val_mae: 38.2793\n",
      "Epoch 114/1000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 39.0291 - mae: 39.0291 - val_loss: 38.2235 - val_mae: 38.2235\n",
      "Epoch 115/1000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 39.0134 - mae: 39.0134 - val_loss: 38.1904 - val_mae: 38.1904\n",
      "Epoch 116/1000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 38.9970 - mae: 38.9970 - val_loss: 38.1727 - val_mae: 38.1727\n",
      "Epoch 117/1000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 38.9795 - mae: 38.9795 - val_loss: 38.1712 - val_mae: 38.1712\n",
      "Epoch 118/1000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 38.9614 - mae: 38.9614 - val_loss: 38.1838 - val_mae: 38.1838\n",
      "Epoch 119/1000\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 38.9427 - mae: 38.9427 - val_loss: 38.2081 - val_mae: 38.2081\n",
      "Epoch 120/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 38.9256 - mae: 38.9256 - val_loss: 38.2150 - val_mae: 38.2150\n",
      "Epoch 121/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 38.9090 - mae: 38.9090 - val_loss: 38.1964 - val_mae: 38.1964\n",
      "Epoch 122/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 38.8911 - mae: 38.8911 - val_loss: 38.1584 - val_mae: 38.1584\n",
      "Epoch 123/1000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 38.8724 - mae: 38.8724 - val_loss: 38.1039 - val_mae: 38.1039\n",
      "Epoch 124/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 38.8531 - mae: 38.8531 - val_loss: 38.0299 - val_mae: 38.0299\n",
      "Epoch 125/1000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 38.8344 - mae: 38.8344 - val_loss: 37.9844 - val_mae: 37.9844\n",
      "Epoch 126/1000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 38.8164 - mae: 38.8164 - val_loss: 37.9501 - val_mae: 37.9501\n",
      "Epoch 127/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 38.7979 - mae: 38.7979 - val_loss: 37.9396 - val_mae: 37.9396\n",
      "Epoch 128/1000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 38.7782 - mae: 38.7782 - val_loss: 37.9429 - val_mae: 37.9429\n",
      "Epoch 129/1000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 38.7579 - mae: 38.7579 - val_loss: 37.9663 - val_mae: 37.9663\n",
      "Epoch 130/1000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 38.7395 - mae: 38.7395 - val_loss: 37.9667 - val_mae: 37.9667\n",
      "Epoch 131/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 38.7208 - mae: 38.7208 - val_loss: 37.9363 - val_mae: 37.9363\n",
      "Epoch 132/1000\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 38.7008 - mae: 38.7008 - val_loss: 37.8877 - val_mae: 37.8877\n",
      "Epoch 133/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 38.6798 - mae: 38.6798 - val_loss: 37.8191 - val_mae: 37.8191\n",
      "Epoch 134/1000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 38.6597 - mae: 38.6597 - val_loss: 37.7706 - val_mae: 37.7706\n",
      "Epoch 135/1000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 38.6422 - mae: 38.6422 - val_loss: 37.7921 - val_mae: 37.7921\n",
      "Epoch 136/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 38.6194 - mae: 38.6194 - val_loss: 37.8250 - val_mae: 37.8250\n",
      "Epoch 137/1000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 38.5996 - mae: 38.5996 - val_loss: 37.8216 - val_mae: 37.8216\n",
      "Epoch 138/1000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 38.5795 - mae: 38.5795 - val_loss: 37.8037 - val_mae: 37.8037\n",
      "Epoch 139/1000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 38.5584 - mae: 38.5584 - val_loss: 37.7566 - val_mae: 37.7566\n",
      "Epoch 140/1000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 38.5365 - mae: 38.5365 - val_loss: 37.6913 - val_mae: 37.6913\n",
      "Epoch 141/1000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 38.5165 - mae: 38.5165 - val_loss: 37.6475 - val_mae: 37.6475\n",
      "Epoch 142/1000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 38.4963 - mae: 38.4963 - val_loss: 37.6237 - val_mae: 37.6237\n",
      "Epoch 143/1000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 38.4751 - mae: 38.4751 - val_loss: 37.6267 - val_mae: 37.6267\n",
      "Epoch 144/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 38.4529 - mae: 38.4529 - val_loss: 37.6450 - val_mae: 37.6450\n",
      "Epoch 145/1000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 38.4299 - mae: 38.4299 - val_loss: 37.6840 - val_mae: 37.6840\n",
      "Epoch 146/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 38.4079 - mae: 38.4079 - val_loss: 37.6838 - val_mae: 37.6838\n",
      "Epoch 147/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 38.3862 - mae: 38.3862 - val_loss: 37.6571 - val_mae: 37.6571\n",
      "Epoch 148/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 38.3630 - mae: 38.3630 - val_loss: 37.6051 - val_mae: 37.6051\n",
      "Epoch 149/1000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 38.3390 - mae: 38.3390 - val_loss: 37.5791 - val_mae: 37.5791\n",
      "Epoch 150/1000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 38.3163 - mae: 38.3163 - val_loss: 37.5763 - val_mae: 37.5763\n",
      "Epoch 151/1000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 38.2930 - mae: 38.2930 - val_loss: 37.5346 - val_mae: 37.5346\n",
      "Epoch 152/1000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 38.2697 - mae: 38.2697 - val_loss: 37.5279 - val_mae: 37.5279\n",
      "Epoch 153/1000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 38.2455 - mae: 38.2455 - val_loss: 37.5342 - val_mae: 37.5342\n",
      "Epoch 154/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 38.2219 - mae: 38.2219 - val_loss: 37.5137 - val_mae: 37.5137\n",
      "Epoch 155/1000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 38.1974 - mae: 38.1974 - val_loss: 37.4582 - val_mae: 37.4582\n",
      "Epoch 156/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 38.1732 - mae: 38.1732 - val_loss: 37.4339 - val_mae: 37.4339\n",
      "Epoch 157/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 38.1485 - mae: 38.1485 - val_loss: 37.4303 - val_mae: 37.4303\n",
      "Epoch 158/1000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 38.1231 - mae: 38.1231 - val_loss: 37.4560 - val_mae: 37.4560\n",
      "Epoch 159/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 38.0980 - mae: 38.0980 - val_loss: 37.4433 - val_mae: 37.4433\n",
      "Epoch 160/1000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 38.0728 - mae: 38.0728 - val_loss: 37.3902 - val_mae: 37.3902\n",
      "Epoch 161/1000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 38.0453 - mae: 38.0453 - val_loss: 37.3725 - val_mae: 37.3725\n",
      "Epoch 162/1000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 38.0190 - mae: 38.0190 - val_loss: 37.3214 - val_mae: 37.3214\n",
      "Epoch 163/1000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 37.9932 - mae: 37.9932 - val_loss: 37.2967 - val_mae: 37.2967\n",
      "Epoch 164/1000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 37.9665 - mae: 37.9665 - val_loss: 37.2957 - val_mae: 37.2957\n",
      "Epoch 165/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 37.9389 - mae: 37.9389 - val_loss: 37.3192 - val_mae: 37.3192\n",
      "Epoch 166/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 37.9121 - mae: 37.9121 - val_loss: 37.3094 - val_mae: 37.3094\n",
      "Epoch 167/1000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 37.8862 - mae: 37.8862 - val_loss: 37.1950 - val_mae: 37.1950\n",
      "Epoch 168/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 37.8567 - mae: 37.8567 - val_loss: 37.1244 - val_mae: 37.1244\n",
      "Epoch 169/1000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 37.8301 - mae: 37.8301 - val_loss: 37.0791 - val_mae: 37.0791\n",
      "Epoch 170/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 37.8023 - mae: 37.8023 - val_loss: 37.0566 - val_mae: 37.0566\n",
      "Epoch 171/1000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 37.7731 - mae: 37.7731 - val_loss: 37.0641 - val_mae: 37.0641\n",
      "Epoch 172/1000\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 37.7429 - mae: 37.7429 - val_loss: 37.1119 - val_mae: 37.1119\n",
      "Epoch 173/1000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 37.7134 - mae: 37.7134 - val_loss: 37.1019 - val_mae: 37.1019\n",
      "Epoch 174/1000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 37.6848 - mae: 37.6848 - val_loss: 37.0525 - val_mae: 37.0525\n",
      "Epoch 175/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 37.6546 - mae: 37.6546 - val_loss: 36.9608 - val_mae: 36.9608\n",
      "Epoch 176/1000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 37.6226 - mae: 37.6226 - val_loss: 36.9167 - val_mae: 36.9167\n",
      "Epoch 177/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 37.5925 - mae: 37.5925 - val_loss: 36.8928 - val_mae: 36.8928\n",
      "Epoch 178/1000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 37.5612 - mae: 37.5612 - val_loss: 36.8986 - val_mae: 36.8986\n",
      "Epoch 179/1000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 37.5318 - mae: 37.5318 - val_loss: 36.8709 - val_mae: 36.8709\n",
      "Epoch 180/1000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 37.5004 - mae: 37.5004 - val_loss: 36.7929 - val_mae: 36.7929\n",
      "Epoch 181/1000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 37.4671 - mae: 37.4671 - val_loss: 36.6773 - val_mae: 36.6773\n",
      "Epoch 182/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 37.4364 - mae: 37.4364 - val_loss: 36.6083 - val_mae: 36.6083\n",
      "Epoch 183/1000\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 37.4043 - mae: 37.4043 - val_loss: 36.5702 - val_mae: 36.5702\n",
      "Epoch 184/1000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 37.3714 - mae: 37.3714 - val_loss: 36.5844 - val_mae: 36.5844\n",
      "Epoch 185/1000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 37.3363 - mae: 37.3363 - val_loss: 36.6014 - val_mae: 36.6014\n",
      "Epoch 186/1000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 37.3025 - mae: 37.3025 - val_loss: 36.5895 - val_mae: 36.5895\n",
      "Epoch 187/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 37.2693 - mae: 37.2693 - val_loss: 36.5200 - val_mae: 36.5200\n",
      "Epoch 188/1000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 37.2336 - mae: 37.2336 - val_loss: 36.4123 - val_mae: 36.4123\n",
      "Epoch 189/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 37.1986 - mae: 37.1986 - val_loss: 36.3497 - val_mae: 36.3497\n",
      "Epoch 190/1000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 37.1634 - mae: 37.1634 - val_loss: 36.3145 - val_mae: 36.3145\n",
      "Epoch 191/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 37.1276 - mae: 37.1276 - val_loss: 36.3225 - val_mae: 36.3225\n",
      "Epoch 192/1000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 37.0899 - mae: 37.0899 - val_loss: 36.2734 - val_mae: 36.2734\n",
      "Epoch 193/1000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 37.0527 - mae: 37.0527 - val_loss: 36.1757 - val_mae: 36.1757\n",
      "Epoch 194/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 37.0172 - mae: 37.0172 - val_loss: 36.1248 - val_mae: 36.1248\n",
      "Epoch 195/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 36.9796 - mae: 36.9796 - val_loss: 36.1108 - val_mae: 36.1108\n",
      "Epoch 196/1000\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 36.9401 - mae: 36.9401 - val_loss: 36.1262 - val_mae: 36.1262\n",
      "Epoch 197/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 36.9023 - mae: 36.9023 - val_loss: 36.0897 - val_mae: 36.0897\n",
      "Epoch 198/1000\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 36.8638 - mae: 36.8638 - val_loss: 36.0113 - val_mae: 36.0113\n",
      "Epoch 199/1000\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 36.8232 - mae: 36.8232 - val_loss: 35.8895 - val_mae: 35.8895\n",
      "Epoch 200/1000\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 36.7839 - mae: 36.7839 - val_loss: 35.8085 - val_mae: 35.8085\n",
      "Epoch 201/1000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 36.7446 - mae: 36.7446 - val_loss: 35.7734 - val_mae: 35.7734\n",
      "Epoch 202/1000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 36.7030 - mae: 36.7030 - val_loss: 35.7528 - val_mae: 35.7528\n",
      "Epoch 203/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 36.6598 - mae: 36.6598 - val_loss: 35.7748 - val_mae: 35.7748\n",
      "Epoch 204/1000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 36.6170 - mae: 36.6170 - val_loss: 35.7475 - val_mae: 35.7475\n",
      "Epoch 205/1000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 36.5756 - mae: 36.5756 - val_loss: 35.6693 - val_mae: 35.6693\n",
      "Epoch 206/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 36.5309 - mae: 36.5309 - val_loss: 35.5558 - val_mae: 35.5558\n",
      "Epoch 207/1000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 36.4880 - mae: 36.4880 - val_loss: 35.4866 - val_mae: 35.4866\n",
      "Epoch 208/1000\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 36.4447 - mae: 36.4447 - val_loss: 35.4438 - val_mae: 35.4438\n",
      "Epoch 209/1000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 36.3988 - mae: 36.3988 - val_loss: 35.4226 - val_mae: 35.4226\n",
      "Epoch 210/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 36.3518 - mae: 36.3518 - val_loss: 35.4436 - val_mae: 35.4436\n",
      "Epoch 211/1000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 36.3072 - mae: 36.3072 - val_loss: 35.4196 - val_mae: 35.4196\n",
      "Epoch 212/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 36.2618 - mae: 36.2618 - val_loss: 35.3379 - val_mae: 35.3379\n",
      "Epoch 213/1000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 36.2130 - mae: 36.2130 - val_loss: 35.2294 - val_mae: 35.2294\n",
      "Epoch 214/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 36.1621 - mae: 36.1621 - val_loss: 35.1427 - val_mae: 35.1427\n",
      "Epoch 215/1000\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 36.1162 - mae: 36.1162 - val_loss: 35.1078 - val_mae: 35.1078\n",
      "Epoch 216/1000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 36.0652 - mae: 36.0652 - val_loss: 35.1082 - val_mae: 35.1082\n",
      "Epoch 217/1000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 36.0159 - mae: 36.0159 - val_loss: 35.0472 - val_mae: 35.0472\n",
      "Epoch 218/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 35.9650 - mae: 35.9650 - val_loss: 34.9686 - val_mae: 34.9686\n",
      "Epoch 219/1000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 35.9122 - mae: 35.9122 - val_loss: 34.8404 - val_mae: 34.8404\n",
      "Epoch 220/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 35.8854 - mae: 35.8854 - val_loss: 35.0669 - val_mae: 35.0669\n",
      "Epoch 221/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 35.8208 - mae: 35.8208 - val_loss: 35.3192 - val_mae: 35.3192\n",
      "Epoch 222/1000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 35.7809 - mae: 35.7809 - val_loss: 35.5390 - val_mae: 35.5390\n",
      "Epoch 223/1000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 35.7569 - mae: 35.7569 - val_loss: 35.3168 - val_mae: 35.3168\n",
      "Epoch 224/1000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 35.6794 - mae: 35.6794 - val_loss: 34.7982 - val_mae: 34.7982\n",
      "Epoch 225/1000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 35.6058 - mae: 35.6058 - val_loss: 34.5322 - val_mae: 34.5322\n",
      "Epoch 226/1000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 35.6344 - mae: 35.6344 - val_loss: 34.4900 - val_mae: 34.4900\n",
      "Epoch 227/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 35.5298 - mae: 35.5298 - val_loss: 35.0634 - val_mae: 35.0634\n",
      "Epoch 228/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 35.4614 - mae: 35.4614 - val_loss: 35.4378 - val_mae: 35.4378\n",
      "Epoch 229/1000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 35.4728 - mae: 35.4728 - val_loss: 35.1434 - val_mae: 35.1434\n",
      "Epoch 230/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 35.3814 - mae: 35.3814 - val_loss: 34.5156 - val_mae: 34.5156\n",
      "Epoch 231/1000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 35.2749 - mae: 35.2749 - val_loss: 34.2450 - val_mae: 34.2450\n",
      "Epoch 232/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 35.2904 - mae: 35.2904 - val_loss: 34.2856 - val_mae: 34.2856\n",
      "Epoch 233/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 35.1720 - mae: 35.1720 - val_loss: 34.7938 - val_mae: 34.7938\n",
      "Epoch 234/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 35.1393 - mae: 35.1393 - val_loss: 34.9170 - val_mae: 34.9170\n",
      "Epoch 235/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 35.1089 - mae: 35.1089 - val_loss: 34.5811 - val_mae: 34.5811\n",
      "Epoch 236/1000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 35.0096 - mae: 35.0096 - val_loss: 34.0309 - val_mae: 34.0309\n",
      "Epoch 237/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 34.9726 - mae: 34.9726 - val_loss: 33.9776 - val_mae: 33.9776\n",
      "Epoch 238/1000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 34.9233 - mae: 34.9233 - val_loss: 34.4598 - val_mae: 34.4598\n",
      "Epoch 239/1000\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 34.8407 - mae: 34.8407 - val_loss: 34.6673 - val_mae: 34.6673\n",
      "Epoch 240/1000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 34.8210 - mae: 34.8210 - val_loss: 34.3290 - val_mae: 34.3290\n",
      "Epoch 241/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 34.7185 - mae: 34.7185 - val_loss: 33.7811 - val_mae: 33.7811\n",
      "Epoch 242/1000\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 34.6857 - mae: 34.6857 - val_loss: 33.7825 - val_mae: 33.7825\n",
      "Epoch 243/1000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 34.5851 - mae: 34.5851 - val_loss: 34.2715 - val_mae: 34.2715\n",
      "Epoch 244/1000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 34.5513 - mae: 34.5513 - val_loss: 34.3311 - val_mae: 34.3311\n",
      "Epoch 245/1000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 34.5065 - mae: 34.5065 - val_loss: 33.8287 - val_mae: 33.8287\n",
      "Epoch 246/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 34.3867 - mae: 34.3867 - val_loss: 33.4884 - val_mae: 33.4884\n",
      "Epoch 247/1000\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 34.4377 - mae: 34.4377 - val_loss: 33.4721 - val_mae: 33.4721\n",
      "Epoch 248/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 34.3016 - mae: 34.3016 - val_loss: 34.1932 - val_mae: 34.1932\n",
      "Epoch 249/1000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 34.2640 - mae: 34.2640 - val_loss: 34.4810 - val_mae: 34.4810\n",
      "Epoch 250/1000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 34.2871 - mae: 34.2871 - val_loss: 33.5227 - val_mae: 33.5227\n",
      "Epoch 251/1000\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 34.0688 - mae: 34.0688 - val_loss: 33.2201 - val_mae: 33.2201\n",
      "Epoch 252/1000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 34.2556 - mae: 34.2556 - val_loss: 33.2090 - val_mae: 33.2090\n",
      "Epoch 253/1000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 33.9647 - mae: 33.9647 - val_loss: 34.5399 - val_mae: 34.5399\n",
      "Epoch 254/1000\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 34.1483 - mae: 34.1483 - val_loss: 34.0909 - val_mae: 34.0909\n",
      "Epoch 255/1000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 33.9374 - mae: 33.9374 - val_loss: 32.9767 - val_mae: 32.9767\n",
      "Epoch 256/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 33.8720 - mae: 33.8720 - val_loss: 32.9431 - val_mae: 32.9431\n",
      "Epoch 257/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 33.9637 - mae: 33.9637 - val_loss: 33.6177 - val_mae: 33.6177\n",
      "Epoch 258/1000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 33.6633 - mae: 33.6633 - val_loss: 34.5520 - val_mae: 34.5520\n",
      "Epoch 259/1000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 33.9830 - mae: 33.9830 - val_loss: 33.4250 - val_mae: 33.4250\n",
      "Epoch 260/1000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 33.5222 - mae: 33.5222 - val_loss: 32.6911 - val_mae: 32.6911\n",
      "Epoch 261/1000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 33.6434 - mae: 33.6434 - val_loss: 32.6369 - val_mae: 32.6369\n",
      "Epoch 262/1000\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 33.4348 - mae: 33.4348 - val_loss: 33.5896 - val_mae: 33.5896\n",
      "Epoch 263/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 33.4199 - mae: 33.4199 - val_loss: 33.6480 - val_mae: 33.6480\n",
      "Epoch 264/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 33.3924 - mae: 33.3924 - val_loss: 32.4902 - val_mae: 32.4902\n",
      "Epoch 265/1000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 33.1988 - mae: 33.1988 - val_loss: 32.3909 - val_mae: 32.3909\n",
      "Epoch 266/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 33.2533 - mae: 33.2533 - val_loss: 32.5450 - val_mae: 32.5450\n",
      "Epoch 267/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 33.0308 - mae: 33.0308 - val_loss: 33.7017 - val_mae: 33.7017\n",
      "Epoch 268/1000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 33.2404 - mae: 33.2404 - val_loss: 32.6673 - val_mae: 32.6673\n",
      "Epoch 269/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 32.8913 - mae: 32.8913 - val_loss: 32.1742 - val_mae: 32.1742\n",
      "Epoch 270/1000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 32.9072 - mae: 32.9072 - val_loss: 32.1085 - val_mae: 32.1085\n",
      "Epoch 271/1000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 32.8867 - mae: 32.8867 - val_loss: 32.9541 - val_mae: 32.9541\n",
      "Epoch 272/1000\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 32.7704 - mae: 32.7704 - val_loss: 33.2242 - val_mae: 33.2242\n",
      "Epoch 273/1000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 32.8410 - mae: 32.8410 - val_loss: 31.9205 - val_mae: 31.9205\n",
      "Epoch 274/1000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 32.6422 - mae: 32.6422 - val_loss: 31.9577 - val_mae: 31.9577\n",
      "Epoch 275/1000\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 32.8802 - mae: 32.8802 - val_loss: 32.9309 - val_mae: 32.9309\n",
      "Epoch 276/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 32.5837 - mae: 32.5837 - val_loss: 33.1115 - val_mae: 33.1115\n",
      "Epoch 277/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 32.6378 - mae: 32.6378 - val_loss: 31.6792 - val_mae: 31.6792\n",
      "Epoch 278/1000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 32.3357 - mae: 32.3357 - val_loss: 31.8969 - val_mae: 31.8969\n",
      "Epoch 279/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 32.8209 - mae: 32.8209 - val_loss: 33.8028 - val_mae: 33.8028\n",
      "Epoch 280/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 32.9778 - mae: 32.9778 - val_loss: 34.6336 - val_mae: 34.6336\n",
      "Epoch 281/1000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 33.4211 - mae: 33.4211 - val_loss: 32.8239 - val_mae: 32.8239\n",
      "Epoch 282/1000\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 32.3694 - mae: 32.3694 - val_loss: 32.0308 - val_mae: 32.0308\n",
      "Epoch 283/1000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 33.1222 - mae: 33.1222 - val_loss: 31.4279 - val_mae: 31.4279\n",
      "Epoch 284/1000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 31.9277 - mae: 31.9277 - val_loss: 33.2065 - val_mae: 33.2065\n",
      "Epoch 285/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 32.4862 - mae: 32.4862 - val_loss: 32.6020 - val_mae: 32.6020\n",
      "Epoch 286/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 32.0904 - mae: 32.0904 - val_loss: 31.2031 - val_mae: 31.2031\n",
      "Epoch 287/1000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 31.8852 - mae: 31.8852 - val_loss: 31.1944 - val_mae: 31.1944\n",
      "Epoch 288/1000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 31.8790 - mae: 31.8790 - val_loss: 31.9303 - val_mae: 31.9303\n",
      "Epoch 289/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 31.6890 - mae: 31.6890 - val_loss: 31.7860 - val_mae: 31.7860\n",
      "Epoch 290/1000\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 31.5939 - mae: 31.5939 - val_loss: 30.9089 - val_mae: 30.9089\n",
      "Epoch 291/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 31.4809 - mae: 31.4809 - val_loss: 30.8746 - val_mae: 30.8746\n",
      "Epoch 292/1000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 31.4856 - mae: 31.4856 - val_loss: 31.7309 - val_mae: 31.7309\n",
      "Epoch 293/1000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 31.4591 - mae: 31.4591 - val_loss: 31.3400 - val_mae: 31.3400\n",
      "Epoch 294/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 31.3078 - mae: 31.3078 - val_loss: 30.6784 - val_mae: 30.6784\n",
      "Epoch 295/1000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 31.2046 - mae: 31.2046 - val_loss: 30.6372 - val_mae: 30.6372\n",
      "Epoch 296/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 31.1234 - mae: 31.1234 - val_loss: 31.0639 - val_mae: 31.0639\n",
      "Epoch 297/1000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 31.0897 - mae: 31.0897 - val_loss: 30.9965 - val_mae: 30.9965\n",
      "Epoch 298/1000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 31.0237 - mae: 31.0237 - val_loss: 30.4598 - val_mae: 30.4598\n",
      "Epoch 299/1000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 30.9166 - mae: 30.9166 - val_loss: 30.4248 - val_mae: 30.4248\n",
      "Epoch 300/1000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 30.8381 - mae: 30.8381 - val_loss: 30.7368 - val_mae: 30.7368\n",
      "Epoch 301/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 30.8043 - mae: 30.8043 - val_loss: 30.4813 - val_mae: 30.4813\n",
      "Epoch 302/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 30.7041 - mae: 30.7041 - val_loss: 30.2609 - val_mae: 30.2609\n",
      "Epoch 303/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 30.6292 - mae: 30.6292 - val_loss: 30.2232 - val_mae: 30.2232\n",
      "Epoch 304/1000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 30.5572 - mae: 30.5572 - val_loss: 30.2417 - val_mae: 30.2417\n",
      "Epoch 305/1000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 30.4870 - mae: 30.4870 - val_loss: 30.1869 - val_mae: 30.1869\n",
      "Epoch 306/1000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 30.4156 - mae: 30.4156 - val_loss: 30.0758 - val_mae: 30.0758\n",
      "Epoch 307/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 30.3392 - mae: 30.3392 - val_loss: 29.9258 - val_mae: 29.9258\n",
      "Epoch 308/1000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 30.2879 - mae: 30.2879 - val_loss: 30.0634 - val_mae: 30.0634\n",
      "Epoch 309/1000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 30.2095 - mae: 30.2095 - val_loss: 29.8627 - val_mae: 29.8627\n",
      "Epoch 310/1000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 30.1201 - mae: 30.1201 - val_loss: 29.7516 - val_mae: 29.7516\n",
      "Epoch 311/1000\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 30.0582 - mae: 30.0582 - val_loss: 30.0111 - val_mae: 30.0111\n",
      "Epoch 312/1000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 30.0376 - mae: 30.0376 - val_loss: 29.6894 - val_mae: 29.6894\n",
      "Epoch 313/1000\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 29.8932 - mae: 29.8932 - val_loss: 29.4781 - val_mae: 29.4781\n",
      "Epoch 314/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 29.9326 - mae: 29.9326 - val_loss: 29.8868 - val_mae: 29.8868\n",
      "Epoch 315/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 29.8536 - mae: 29.8536 - val_loss: 29.6314 - val_mae: 29.6314\n",
      "Epoch 316/1000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 29.7010 - mae: 29.7010 - val_loss: 29.4887 - val_mae: 29.4887\n",
      "Epoch 317/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 29.9514 - mae: 29.9514 - val_loss: 29.9183 - val_mae: 29.9183\n",
      "Epoch 318/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 29.7332 - mae: 29.7332 - val_loss: 30.2473 - val_mae: 30.2473\n",
      "Epoch 319/1000\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 29.8037 - mae: 29.8037 - val_loss: 29.2807 - val_mae: 29.2807\n",
      "Epoch 320/1000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 29.3780 - mae: 29.3780 - val_loss: 29.5185 - val_mae: 29.5185\n",
      "Epoch 321/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 30.0918 - mae: 30.0918 - val_loss: 30.7910 - val_mae: 30.7910\n",
      "Epoch 322/1000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 29.9187 - mae: 29.9187 - val_loss: 31.2025 - val_mae: 31.2025\n",
      "Epoch 323/1000\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 30.0832 - mae: 30.0832 - val_loss: 28.8712 - val_mae: 28.8712\n",
      "Epoch 324/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 29.2582 - mae: 29.2582 - val_loss: 29.0691 - val_mae: 29.0691\n",
      "Epoch 325/1000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 29.5456 - mae: 29.5456 - val_loss: 31.3316 - val_mae: 31.3316\n",
      "Epoch 326/1000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 30.0443 - mae: 30.0443 - val_loss: 30.9283 - val_mae: 30.9283\n",
      "Epoch 327/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 29.7904 - mae: 29.7904 - val_loss: 28.8228 - val_mae: 28.8228\n",
      "Epoch 328/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 29.2676 - mae: 29.2676 - val_loss: 28.5583 - val_mae: 28.5583\n",
      "Epoch 329/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 28.7381 - mae: 28.7381 - val_loss: 29.3426 - val_mae: 29.3426\n",
      "Epoch 330/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 28.9960 - mae: 28.9960 - val_loss: 29.0150 - val_mae: 29.0150\n",
      "Epoch 331/1000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 28.7994 - mae: 28.7994 - val_loss: 28.4561 - val_mae: 28.4561\n",
      "Epoch 332/1000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 28.8284 - mae: 28.8284 - val_loss: 28.5701 - val_mae: 28.5701\n",
      "Epoch 333/1000\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 28.5013 - mae: 28.5013 - val_loss: 28.4722 - val_mae: 28.4722\n",
      "Epoch 334/1000\n",
      "1/1 [==============================] - 0s 124ms/step - loss: 28.4130 - mae: 28.4130 - val_loss: 28.2063 - val_mae: 28.2063\n",
      "Epoch 335/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 28.4941 - mae: 28.4941 - val_loss: 28.5893 - val_mae: 28.5893\n",
      "Epoch 336/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 28.4006 - mae: 28.4006 - val_loss: 28.3835 - val_mae: 28.3835\n",
      "Epoch 337/1000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 28.2516 - mae: 28.2516 - val_loss: 28.0883 - val_mae: 28.0883\n",
      "Epoch 338/1000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 28.4361 - mae: 28.4361 - val_loss: 28.5610 - val_mae: 28.5610\n",
      "Epoch 339/1000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 28.2574 - mae: 28.2574 - val_loss: 28.7091 - val_mae: 28.7091\n",
      "Epoch 340/1000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 28.2823 - mae: 28.2823 - val_loss: 27.7462 - val_mae: 27.7462\n",
      "Epoch 341/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 27.9257 - mae: 27.9257 - val_loss: 27.8160 - val_mae: 27.8160\n",
      "Epoch 342/1000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 28.1326 - mae: 28.1326 - val_loss: 29.5614 - val_mae: 29.5614\n",
      "Epoch 343/1000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 28.4884 - mae: 28.4884 - val_loss: 28.5074 - val_mae: 28.5074\n",
      "Epoch 344/1000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 28.0234 - mae: 28.0234 - val_loss: 27.9134 - val_mae: 27.9134\n",
      "Epoch 345/1000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 28.4205 - mae: 28.4205 - val_loss: 28.1559 - val_mae: 28.1559\n",
      "Epoch 346/1000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 27.7681 - mae: 27.7681 - val_loss: 28.5746 - val_mae: 28.5746\n",
      "Epoch 347/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 27.9229 - mae: 27.9229 - val_loss: 27.2679 - val_mae: 27.2679\n",
      "Epoch 348/1000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 27.3649 - mae: 27.3649 - val_loss: 27.5477 - val_mae: 27.5477\n",
      "Epoch 349/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 28.0223 - mae: 28.0223 - val_loss: 29.3036 - val_mae: 29.3036\n",
      "Epoch 350/1000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 28.1048 - mae: 28.1048 - val_loss: 28.5859 - val_mae: 28.5859\n",
      "Epoch 351/1000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 27.7474 - mae: 27.7474 - val_loss: 27.2155 - val_mae: 27.2155\n",
      "Epoch 352/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 27.5450 - mae: 27.5450 - val_loss: 27.3244 - val_mae: 27.3244\n",
      "Epoch 353/1000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 27.0477 - mae: 27.0477 - val_loss: 27.2348 - val_mae: 27.2348\n",
      "Epoch 354/1000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 26.9634 - mae: 26.9634 - val_loss: 26.9529 - val_mae: 26.9529\n",
      "Epoch 355/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 27.1306 - mae: 27.1306 - val_loss: 28.0518 - val_mae: 28.0518\n",
      "Epoch 356/1000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 27.3125 - mae: 27.3125 - val_loss: 27.6790 - val_mae: 27.6790\n",
      "Epoch 357/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 27.0960 - mae: 27.0960 - val_loss: 26.8272 - val_mae: 26.8272\n",
      "Epoch 358/1000\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 27.1380 - mae: 27.1380 - val_loss: 27.2285 - val_mae: 27.2285\n",
      "Epoch 359/1000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 26.7760 - mae: 26.7760 - val_loss: 26.9354 - val_mae: 26.9354\n",
      "Epoch 360/1000\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 26.5655 - mae: 26.5655 - val_loss: 26.5748 - val_mae: 26.5748\n",
      "Epoch 361/1000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 26.7508 - mae: 26.7508 - val_loss: 27.7148 - val_mae: 27.7148\n",
      "Epoch 362/1000\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 26.9130 - mae: 26.9130 - val_loss: 27.1430 - val_mae: 27.1430\n",
      "Epoch 363/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 26.5833 - mae: 26.5833 - val_loss: 26.6409 - val_mae: 26.6409\n",
      "Epoch 364/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 27.0759 - mae: 27.0759 - val_loss: 26.9444 - val_mae: 26.9444\n",
      "Epoch 365/1000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 26.3956 - mae: 26.3956 - val_loss: 26.9870 - val_mae: 26.9870\n",
      "Epoch 366/1000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 26.3782 - mae: 26.3782 - val_loss: 26.1949 - val_mae: 26.1949\n",
      "Epoch 367/1000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 26.3851 - mae: 26.3851 - val_loss: 26.7831 - val_mae: 26.7831\n",
      "Epoch 368/1000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 26.1872 - mae: 26.1872 - val_loss: 26.4642 - val_mae: 26.4642\n",
      "Epoch 369/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 25.9746 - mae: 25.9746 - val_loss: 26.0269 - val_mae: 26.0269\n",
      "Epoch 370/1000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 26.2846 - mae: 26.2846 - val_loss: 26.8515 - val_mae: 26.8515\n",
      "Epoch 371/1000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 26.1251 - mae: 26.1251 - val_loss: 26.1473 - val_mae: 26.1473\n",
      "Epoch 372/1000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 25.7124 - mae: 25.7124 - val_loss: 25.9919 - val_mae: 25.9919\n",
      "Epoch 373/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 26.3421 - mae: 26.3421 - val_loss: 27.0640 - val_mae: 27.0640\n",
      "Epoch 374/1000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 26.1611 - mae: 26.1611 - val_loss: 25.9069 - val_mae: 25.9069\n",
      "Epoch 375/1000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 25.4757 - mae: 25.4757 - val_loss: 25.8539 - val_mae: 25.8539\n",
      "Epoch 376/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 26.2759 - mae: 26.2759 - val_loss: 26.5968 - val_mae: 26.5968\n",
      "Epoch 377/1000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 25.7768 - mae: 25.7768 - val_loss: 25.8245 - val_mae: 25.8245\n",
      "Epoch 378/1000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 25.3411 - mae: 25.3411 - val_loss: 25.4640 - val_mae: 25.4640\n",
      "Epoch 379/1000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 25.9002 - mae: 25.9002 - val_loss: 25.8854 - val_mae: 25.8854\n",
      "Epoch 380/1000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 25.2772 - mae: 25.2772 - val_loss: 25.6385 - val_mae: 25.6385\n",
      "Epoch 381/1000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 25.0746 - mae: 25.0746 - val_loss: 25.1213 - val_mae: 25.1213\n",
      "Epoch 382/1000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 25.1294 - mae: 25.1294 - val_loss: 25.4718 - val_mae: 25.4718\n",
      "Epoch 383/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 24.9257 - mae: 24.9257 - val_loss: 25.3060 - val_mae: 25.3060\n",
      "Epoch 384/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 24.8100 - mae: 24.8100 - val_loss: 24.8871 - val_mae: 24.8871\n",
      "Epoch 385/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 24.8430 - mae: 24.8430 - val_loss: 25.2947 - val_mae: 25.2947\n",
      "Epoch 386/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 24.7444 - mae: 24.7444 - val_loss: 24.9544 - val_mae: 24.9544\n",
      "Epoch 387/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 24.5513 - mae: 24.5513 - val_loss: 24.7173 - val_mae: 24.7173\n",
      "Epoch 388/1000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 24.5441 - mae: 24.5441 - val_loss: 24.8398 - val_mae: 24.8398\n",
      "Epoch 389/1000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 24.4075 - mae: 24.4075 - val_loss: 24.6834 - val_mae: 24.6834\n",
      "Epoch 390/1000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 24.3044 - mae: 24.3044 - val_loss: 24.5358 - val_mae: 24.5358\n",
      "Epoch 391/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 24.3781 - mae: 24.3781 - val_loss: 25.9161 - val_mae: 25.9161\n",
      "Epoch 392/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 25.0902 - mae: 25.0902 - val_loss: 26.3713 - val_mae: 26.3713\n",
      "Epoch 393/1000\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 26.9466 - mae: 26.9466 - val_loss: 24.8798 - val_mae: 24.8798\n",
      "Epoch 394/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 24.3588 - mae: 24.3588 - val_loss: 27.6021 - val_mae: 27.6021\n",
      "Epoch 395/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 26.4960 - mae: 26.4960 - val_loss: 31.6695 - val_mae: 31.6695\n",
      "Epoch 396/1000\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 32.2701 - mae: 32.2701 - val_loss: 24.3688 - val_mae: 24.3688\n",
      "Epoch 397/1000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 24.6654 - mae: 24.6654 - val_loss: 45.4908 - val_mae: 45.4908\n",
      "Epoch 398/1000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 44.5859 - mae: 44.5859 - val_loss: 32.8043 - val_mae: 32.8043\n",
      "Epoch 399/1000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 33.3753 - mae: 33.3753 - val_loss: 38.1356 - val_mae: 38.1356\n",
      "Epoch 400/1000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 39.7760 - mae: 39.7760 - val_loss: 28.0364 - val_mae: 28.0364\n",
      "Epoch 401/1000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 26.7894 - mae: 26.7894 - val_loss: 44.8570 - val_mae: 44.8570\n",
      "Epoch 402/1000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 43.7389 - mae: 43.7389 - val_loss: 27.9258 - val_mae: 27.9258\n",
      "Epoch 403/1000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 28.4413 - mae: 28.4413 - val_loss: 39.5968 - val_mae: 39.5968\n",
      "Epoch 404/1000\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 41.3269 - mae: 41.3269 - val_loss: 26.5137 - val_mae: 26.5137\n",
      "Epoch 405/1000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 27.0422 - mae: 27.0422 - val_loss: 39.0525 - val_mae: 39.0525\n",
      "Epoch 406/1000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 37.4872 - mae: 37.4872 - val_loss: 27.0976 - val_mae: 27.0976\n",
      "Epoch 407/1000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 26.2901 - mae: 26.2901 - val_loss: 29.2998 - val_mae: 29.2998\n",
      "Epoch 408/1000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 29.8653 - mae: 29.8653 - val_loss: 31.5939 - val_mae: 31.5939\n",
      "Epoch 409/1000\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 32.1344 - mae: 32.1344 - val_loss: 25.8417 - val_mae: 25.8417\n",
      "Epoch 410/1000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 25.8927 - mae: 25.8927 - val_loss: 32.7751 - val_mae: 32.7751\n",
      "Epoch 411/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 30.8410 - mae: 30.8410 - val_loss: 28.9718 - val_mae: 28.9718\n",
      "Epoch 412/1000\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 27.3808 - mae: 27.3808 - val_loss: 25.3557 - val_mae: 25.3557\n",
      "Epoch 413/1000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 25.8297 - mae: 25.8297 - val_loss: 27.4768 - val_mae: 27.4768\n",
      "Epoch 414/1000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 28.2629 - mae: 28.2629 - val_loss: 25.8658 - val_mae: 25.8658\n",
      "Epoch 415/1000\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 26.5476 - mae: 26.5476 - val_loss: 27.0452 - val_mae: 27.0452\n",
      "Epoch 416/1000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 26.4211 - mae: 26.4211 - val_loss: 29.5201 - val_mae: 29.5201\n",
      "Epoch 417/1000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 27.8386 - mae: 27.8386 - val_loss: 27.7547 - val_mae: 27.7547\n",
      "Epoch 418/1000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 26.5379 - mae: 26.5379 - val_loss: 25.1044 - val_mae: 25.1044\n",
      "Epoch 419/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 25.2587 - mae: 25.2587 - val_loss: 26.3503 - val_mae: 26.3503\n",
      "Epoch 420/1000\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 26.9755 - mae: 26.9755 - val_loss: 25.5965 - val_mae: 25.5965\n",
      "Epoch 421/1000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 25.8675 - mae: 25.8675 - val_loss: 26.8518 - val_mae: 26.8518\n",
      "Epoch 422/1000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 25.9778 - mae: 25.9778 - val_loss: 28.6291 - val_mae: 28.6291\n",
      "Epoch 423/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 27.1566 - mae: 27.1566 - val_loss: 25.6726 - val_mae: 25.6726\n",
      "Epoch 424/1000\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 25.3289 - mae: 25.3289 - val_loss: 26.1477 - val_mae: 26.1477\n",
      "Epoch 425/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 26.6176 - mae: 26.6176 - val_loss: 25.8048 - val_mae: 25.8048\n",
      "Epoch 426/1000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 26.1718 - mae: 26.1718 - val_loss: 26.1128 - val_mae: 26.1128\n",
      "Epoch 427/1000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 25.4465 - mae: 25.4465 - val_loss: 27.9356 - val_mae: 27.9356\n",
      "Epoch 428/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 26.7178 - mae: 26.7178 - val_loss: 25.5925 - val_mae: 25.5925\n",
      "Epoch 429/1000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 25.2082 - mae: 25.2082 - val_loss: 25.7454 - val_mae: 25.7454\n",
      "Epoch 430/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 26.1268 - mae: 26.1268 - val_loss: 25.4244 - val_mae: 25.4244\n",
      "Epoch 431/1000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 25.6750 - mae: 25.6750 - val_loss: 25.9816 - val_mae: 25.9816\n",
      "Epoch 432/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 25.3002 - mae: 25.3002 - val_loss: 27.0290 - val_mae: 27.0290\n",
      "Epoch 433/1000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 26.0257 - mae: 26.0257 - val_loss: 25.3192 - val_mae: 25.3192\n",
      "Epoch 434/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 25.0130 - mae: 25.0130 - val_loss: 25.7187 - val_mae: 25.7187\n",
      "Epoch 435/1000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 26.1378 - mae: 26.1378 - val_loss: 25.2483 - val_mae: 25.2483\n",
      "Epoch 436/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 25.2105 - mae: 25.2105 - val_loss: 26.3472 - val_mae: 26.3472\n",
      "Epoch 437/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 25.4794 - mae: 25.4794 - val_loss: 26.1768 - val_mae: 26.1768\n",
      "Epoch 438/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 25.3334 - mae: 25.3334 - val_loss: 25.1537 - val_mae: 25.1537\n",
      "Epoch 439/1000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 25.0205 - mae: 25.0205 - val_loss: 25.1496 - val_mae: 25.1496\n",
      "Epoch 440/1000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 25.2913 - mae: 25.2913 - val_loss: 25.1371 - val_mae: 25.1371\n",
      "Epoch 441/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 24.7608 - mae: 24.7608 - val_loss: 25.7233 - val_mae: 25.7233\n",
      "Epoch 442/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 24.9961 - mae: 24.9961 - val_loss: 25.3043 - val_mae: 25.3043\n",
      "Epoch 443/1000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 24.7813 - mae: 24.7813 - val_loss: 24.9853 - val_mae: 24.9853\n",
      "Epoch 444/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 24.6810 - mae: 24.6810 - val_loss: 24.9606 - val_mae: 24.9606\n",
      "Epoch 445/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 24.7739 - mae: 24.7739 - val_loss: 25.0440 - val_mae: 25.0440\n",
      "Epoch 446/1000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 24.6015 - mae: 24.6015 - val_loss: 25.8435 - val_mae: 25.8435\n",
      "Epoch 447/1000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 24.9935 - mae: 24.9935 - val_loss: 24.8522 - val_mae: 24.8522\n",
      "Epoch 448/1000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 24.5112 - mae: 24.5112 - val_loss: 24.9036 - val_mae: 24.9036\n",
      "Epoch 449/1000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 25.0902 - mae: 25.0902 - val_loss: 24.7931 - val_mae: 24.7931\n",
      "Epoch 450/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 24.4126 - mae: 24.4126 - val_loss: 25.6217 - val_mae: 25.6217\n",
      "Epoch 451/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 24.8181 - mae: 24.8181 - val_loss: 24.7270 - val_mae: 24.7270\n",
      "Epoch 452/1000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 24.3301 - mae: 24.3301 - val_loss: 24.7364 - val_mae: 24.7364\n",
      "Epoch 453/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 24.8172 - mae: 24.8172 - val_loss: 24.6472 - val_mae: 24.6472\n",
      "Epoch 454/1000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 24.2688 - mae: 24.2688 - val_loss: 25.4884 - val_mae: 25.4884\n",
      "Epoch 455/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 24.7206 - mae: 24.7206 - val_loss: 24.5731 - val_mae: 24.5731\n",
      "Epoch 456/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 24.2057 - mae: 24.2057 - val_loss: 24.5593 - val_mae: 24.5593\n",
      "Epoch 457/1000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 24.3923 - mae: 24.3923 - val_loss: 24.6437 - val_mae: 24.6437\n",
      "Epoch 458/1000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 24.1559 - mae: 24.1559 - val_loss: 24.8734 - val_mae: 24.8734\n",
      "Epoch 459/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 24.2724 - mae: 24.2724 - val_loss: 24.4417 - val_mae: 24.4417\n",
      "Epoch 460/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 24.1090 - mae: 24.1090 - val_loss: 24.4109 - val_mae: 24.4109\n",
      "Epoch 461/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 24.0939 - mae: 24.0939 - val_loss: 25.0624 - val_mae: 25.0624\n",
      "Epoch 462/1000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 24.3840 - mae: 24.3840 - val_loss: 24.3510 - val_mae: 24.3510\n",
      "Epoch 463/1000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 23.9054 - mae: 23.9054 - val_loss: 24.3360 - val_mae: 24.3360\n",
      "Epoch 464/1000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 24.2508 - mae: 24.2508 - val_loss: 24.3489 - val_mae: 24.3489\n",
      "Epoch 465/1000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 23.8415 - mae: 23.8415 - val_loss: 24.7297 - val_mae: 24.7297\n",
      "Epoch 466/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 24.1432 - mae: 24.1432 - val_loss: 24.2233 - val_mae: 24.2233\n",
      "Epoch 467/1000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 23.9963 - mae: 23.9963 - val_loss: 24.1687 - val_mae: 24.1687\n",
      "Epoch 468/1000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 23.7574 - mae: 23.7574 - val_loss: 24.5530 - val_mae: 24.5530\n",
      "Epoch 469/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 23.9717 - mae: 23.9717 - val_loss: 24.1237 - val_mae: 24.1237\n",
      "Epoch 470/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 23.8683 - mae: 23.8683 - val_loss: 24.1465 - val_mae: 24.1465\n",
      "Epoch 471/1000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 23.6536 - mae: 23.6536 - val_loss: 24.5325 - val_mae: 24.5325\n",
      "Epoch 472/1000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 23.9321 - mae: 23.9321 - val_loss: 24.0702 - val_mae: 24.0702\n",
      "Epoch 473/1000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 23.9878 - mae: 23.9878 - val_loss: 24.0445 - val_mae: 24.0445\n",
      "Epoch 474/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 23.5753 - mae: 23.5753 - val_loss: 24.3163 - val_mae: 24.3163\n",
      "Epoch 475/1000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 23.7123 - mae: 23.7123 - val_loss: 23.9858 - val_mae: 23.9858\n",
      "Epoch 476/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 23.9004 - mae: 23.9004 - val_loss: 24.0377 - val_mae: 24.0377\n",
      "Epoch 477/1000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 23.5084 - mae: 23.5084 - val_loss: 24.4904 - val_mae: 24.4904\n",
      "Epoch 478/1000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 23.8493 - mae: 23.8493 - val_loss: 23.8984 - val_mae: 23.8984\n",
      "Epoch 479/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 23.7996 - mae: 23.7996 - val_loss: 23.8730 - val_mae: 23.8730\n",
      "Epoch 480/1000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 23.4694 - mae: 23.4694 - val_loss: 24.7099 - val_mae: 24.7099\n",
      "Epoch 481/1000\n",
      "1/1 [==============================] - 0s 163ms/step - loss: 24.1242 - mae: 24.1242 - val_loss: 24.3111 - val_mae: 24.3111\n",
      "Epoch 482/1000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 24.5726 - mae: 24.5726 - val_loss: 23.7804 - val_mae: 23.7804\n",
      "Epoch 483/1000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 23.6431 - mae: 23.6431 - val_loss: 26.2156 - val_mae: 26.2156\n",
      "Epoch 484/1000\n",
      "1/1 [==============================] - 0s 118ms/step - loss: 25.3260 - mae: 25.3260 - val_loss: 24.0925 - val_mae: 24.0925\n",
      "Epoch 485/1000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 24.2361 - mae: 24.2361 - val_loss: 24.0265 - val_mae: 24.0265\n",
      "Epoch 486/1000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 24.1313 - mae: 24.1313 - val_loss: 25.6149 - val_mae: 25.6149\n",
      "Epoch 487/1000\n",
      "1/1 [==============================] - 0s 151ms/step - loss: 24.8470 - mae: 24.8470 - val_loss: 23.6919 - val_mae: 23.6919\n",
      "Epoch 488/1000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 23.4698 - mae: 23.4698 - val_loss: 23.6904 - val_mae: 23.6904\n",
      "Epoch 489/1000\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 23.5523 - mae: 23.5523 - val_loss: 24.5069 - val_mae: 24.5069\n",
      "Epoch 490/1000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 23.9037 - mae: 23.9037 - val_loss: 23.8840 - val_mae: 23.8840\n",
      "Epoch 491/1000\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 23.9432 - mae: 23.9432 - val_loss: 23.6363 - val_mae: 23.6363\n",
      "Epoch 492/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 23.4078 - mae: 23.4078 - val_loss: 25.2012 - val_mae: 25.2012\n",
      "Epoch 493/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 24.5332 - mae: 24.5332 - val_loss: 24.0615 - val_mae: 24.0615\n",
      "Epoch 494/1000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 24.2680 - mae: 24.2680 - val_loss: 23.6461 - val_mae: 23.6461\n",
      "Epoch 495/1000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 23.5565 - mae: 23.5565 - val_loss: 26.4389 - val_mae: 26.4389\n",
      "Epoch 496/1000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 25.5197 - mae: 25.5197 - val_loss: 24.4527 - val_mae: 24.4527\n",
      "Epoch 497/1000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 24.8158 - mae: 24.8158 - val_loss: 24.1741 - val_mae: 24.1741\n",
      "Epoch 498/1000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 24.4590 - mae: 24.4590 - val_loss: 26.3375 - val_mae: 26.3375\n",
      "Epoch 499/1000\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 25.4363 - mae: 25.4363 - val_loss: 23.6525 - val_mae: 23.6525\n",
      "Epoch 500/1000\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 23.6382 - mae: 23.6382 - val_loss: 24.0011 - val_mae: 24.0011\n",
      "Epoch 501/1000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 24.2068 - mae: 24.2068 - val_loss: 24.8127 - val_mae: 24.8127\n",
      "Epoch 502/1000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 24.1814 - mae: 24.1814 - val_loss: 23.5494 - val_mae: 23.5494\n",
      "Epoch 503/1000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 23.2765 - mae: 23.2765 - val_loss: 23.6830 - val_mae: 23.6830\n",
      "Epoch 504/1000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 23.7086 - mae: 23.7086 - val_loss: 24.3904 - val_mae: 24.3904\n",
      "Epoch 505/1000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 23.7704 - mae: 23.7704 - val_loss: 23.6457 - val_mae: 23.6457\n",
      "Epoch 506/1000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 23.6480 - mae: 23.6480 - val_loss: 23.5174 - val_mae: 23.5174\n",
      "Epoch 507/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 23.3658 - mae: 23.3658 - val_loss: 24.8178 - val_mae: 24.8178\n",
      "Epoch 508/1000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 24.1657 - mae: 24.1657 - val_loss: 23.8447 - val_mae: 23.8447\n",
      "Epoch 509/1000\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 24.0032 - mae: 24.0032 - val_loss: 23.4988 - val_mae: 23.4988\n",
      "Epoch 510/1000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 23.3443 - mae: 23.3443 - val_loss: 25.0874 - val_mae: 25.0874\n",
      "Epoch 511/1000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 24.3915 - mae: 24.3915 - val_loss: 23.7506 - val_mae: 23.7506\n",
      "Epoch 512/1000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 23.8794 - mae: 23.8794 - val_loss: 23.6241 - val_mae: 23.6241\n",
      "Epoch 513/1000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 23.6420 - mae: 23.6420 - val_loss: 25.3376 - val_mae: 25.3376\n",
      "Epoch 514/1000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 24.6148 - mae: 24.6148 - val_loss: 23.9245 - val_mae: 23.9245\n",
      "Epoch 515/1000\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 24.1427 - mae: 24.1427 - val_loss: 23.6087 - val_mae: 23.6087\n",
      "Epoch 516/1000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 23.6276 - mae: 23.6276 - val_loss: 26.1776 - val_mae: 26.1776\n",
      "Epoch 517/1000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 25.3201 - mae: 25.3201 - val_loss: 23.9738 - val_mae: 23.9738\n",
      "Epoch 518/1000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 24.2150 - mae: 24.2150 - val_loss: 23.9061 - val_mae: 23.9061\n",
      "Epoch 519/1000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 24.1276 - mae: 24.1276 - val_loss: 26.0673 - val_mae: 26.0673\n",
      "Epoch 520/1000\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 25.2315 - mae: 25.2315 - val_loss: 23.6332 - val_mae: 23.6332\n",
      "Epoch 521/1000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 23.7064 - mae: 23.7064 - val_loss: 23.6570 - val_mae: 23.6570\n",
      "Epoch 522/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 23.7640 - mae: 23.7640 - val_loss: 24.9966 - val_mae: 24.9966\n",
      "Epoch 523/1000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 24.2927 - mae: 24.2927 - val_loss: 23.5968 - val_mae: 23.5968\n",
      "Epoch 524/1000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 23.6408 - mae: 23.6408 - val_loss: 23.4631 - val_mae: 23.4631\n",
      "Epoch 525/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 23.3917 - mae: 23.3917 - val_loss: 24.9459 - val_mae: 24.9459\n",
      "Epoch 526/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 24.2430 - mae: 24.2430 - val_loss: 23.6884 - val_mae: 23.6884\n",
      "Epoch 527/1000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 23.8263 - mae: 23.8263 - val_loss: 23.4439 - val_mae: 23.4439\n",
      "Epoch 528/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 23.3668 - mae: 23.3668 - val_loss: 25.1113 - val_mae: 25.1113\n",
      "Epoch 529/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 24.3838 - mae: 24.3838 - val_loss: 23.7853 - val_mae: 23.7853\n",
      "Epoch 530/1000\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 23.9753 - mae: 23.9753 - val_loss: 23.5769 - val_mae: 23.5769\n",
      "Epoch 531/1000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 23.6333 - mae: 23.6333 - val_loss: 25.7520 - val_mae: 25.7520\n",
      "Epoch 532/1000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 24.9614 - mae: 24.9614 - val_loss: 23.7784 - val_mae: 23.7784\n",
      "Epoch 533/1000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 23.9738 - mae: 23.9738 - val_loss: 23.7067 - val_mae: 23.7067\n",
      "Epoch 534/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 23.8690 - mae: 23.8690 - val_loss: 25.3874 - val_mae: 25.3874\n",
      "Epoch 535/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 24.6194 - mae: 24.6194 - val_loss: 23.4562 - val_mae: 23.4562\n",
      "Epoch 536/1000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 23.4120 - mae: 23.4120 - val_loss: 23.5355 - val_mae: 23.5355\n",
      "Epoch 537/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 23.5709 - mae: 23.5709 - val_loss: 24.4338 - val_mae: 24.4338\n",
      "Epoch 538/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 23.7976 - mae: 23.7976 - val_loss: 23.4089 - val_mae: 23.4089\n",
      "Epoch 539/1000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 23.3147 - mae: 23.3147 - val_loss: 23.4036 - val_mae: 23.4036\n",
      "Epoch 540/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 23.3050 - mae: 23.3050 - val_loss: 24.0469 - val_mae: 24.0469\n",
      "Epoch 541/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 23.4448 - mae: 23.4448 - val_loss: 23.3798 - val_mae: 23.3798\n",
      "Epoch 542/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 23.2137 - mae: 23.2137 - val_loss: 23.4517 - val_mae: 23.4517\n",
      "Epoch 543/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 23.4293 - mae: 23.4293 - val_loss: 24.0334 - val_mae: 24.0334\n",
      "Epoch 544/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 23.4357 - mae: 23.4357 - val_loss: 23.3878 - val_mae: 23.3878\n",
      "Epoch 545/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 23.1353 - mae: 23.1353 - val_loss: 23.4252 - val_mae: 23.4252\n",
      "Epoch 546/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 23.3824 - mae: 23.3824 - val_loss: 23.8655 - val_mae: 23.8655\n",
      "Epoch 547/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 23.3126 - mae: 23.3126 - val_loss: 23.5848 - val_mae: 23.5848\n",
      "Epoch 548/1000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 23.1637 - mae: 23.1637 - val_loss: 23.4968 - val_mae: 23.4968\n",
      "Epoch 549/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 23.5439 - mae: 23.5439 - val_loss: 23.5646 - val_mae: 23.5646\n",
      "Epoch 550/1000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 23.1553 - mae: 23.1553 - val_loss: 23.7738 - val_mae: 23.7738\n",
      "Epoch 551/1000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 23.2625 - mae: 23.2625 - val_loss: 23.3539 - val_mae: 23.3539\n",
      "Epoch 552/1000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 23.2082 - mae: 23.2082 - val_loss: 23.3775 - val_mae: 23.3775\n",
      "Epoch 553/1000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 23.2793 - mae: 23.2793 - val_loss: 24.1345 - val_mae: 24.1345\n",
      "Epoch 554/1000\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 23.5244 - mae: 23.5244 - val_loss: 23.3549 - val_mae: 23.3549\n",
      "Epoch 555/1000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 23.2403 - mae: 23.2403 - val_loss: 23.4355 - val_mae: 23.4355\n",
      "Epoch 556/1000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 23.4466 - mae: 23.4466 - val_loss: 24.3137 - val_mae: 24.3137\n",
      "Epoch 557/1000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 23.6682 - mae: 23.6682 - val_loss: 23.3421 - val_mae: 23.3421\n",
      "Epoch 558/1000\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 23.2177 - mae: 23.2177 - val_loss: 23.6339 - val_mae: 23.6339\n",
      "Epoch 559/1000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 23.7842 - mae: 23.7842 - val_loss: 23.8470 - val_mae: 23.8470\n",
      "Epoch 560/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 23.3188 - mae: 23.3188 - val_loss: 24.0240 - val_mae: 24.0240\n",
      "Epoch 561/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 23.4358 - mae: 23.4358 - val_loss: 23.7773 - val_mae: 23.7773\n",
      "Epoch 562/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 23.9950 - mae: 23.9950 - val_loss: 23.3204 - val_mae: 23.3204\n",
      "Epoch 563/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 23.1446 - mae: 23.1446 - val_loss: 24.9509 - val_mae: 24.9509\n",
      "Epoch 564/1000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 24.2054 - mae: 24.2054 - val_loss: 24.1566 - val_mae: 24.1566\n",
      "Epoch 565/1000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 24.4693 - mae: 24.4693 - val_loss: 23.5530 - val_mae: 23.5530\n",
      "Epoch 566/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 23.6581 - mae: 23.6581 - val_loss: 26.5381 - val_mae: 26.5381\n",
      "Epoch 567/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 25.7238 - mae: 25.7238 - val_loss: 24.4662 - val_mae: 24.4662\n",
      "Epoch 568/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 24.7595 - mae: 24.7595 - val_loss: 24.4694 - val_mae: 24.4694\n",
      "Epoch 569/1000\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 24.7623 - mae: 24.7623 - val_loss: 25.4858 - val_mae: 25.4858\n",
      "Epoch 570/1000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 24.6701 - mae: 24.6701 - val_loss: 23.3047 - val_mae: 23.3047\n",
      "Epoch 571/1000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 23.1579 - mae: 23.1579 - val_loss: 24.1016 - val_mae: 24.1016\n",
      "Epoch 572/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 24.4097 - mae: 24.4097 - val_loss: 23.7200 - val_mae: 23.7200\n",
      "Epoch 573/1000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 23.2511 - mae: 23.2511 - val_loss: 24.8629 - val_mae: 24.8629\n",
      "Epoch 574/1000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 24.1317 - mae: 24.1317 - val_loss: 25.1390 - val_mae: 25.1390\n",
      "Epoch 575/1000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 25.4560 - mae: 25.4560 - val_loss: 24.0229 - val_mae: 24.0229\n",
      "Epoch 576/1000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 24.3267 - mae: 24.3267 - val_loss: 26.8866 - val_mae: 26.8866\n",
      "Epoch 577/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 26.0835 - mae: 26.0835 - val_loss: 23.4247 - val_mae: 23.4247\n",
      "Epoch 578/1000\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 23.4630 - mae: 23.4630 - val_loss: 23.9809 - val_mae: 23.9809\n",
      "Epoch 579/1000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 24.2817 - mae: 24.2817 - val_loss: 24.2061 - val_mae: 24.2061\n",
      "Epoch 580/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 23.5740 - mae: 23.5740 - val_loss: 23.4922 - val_mae: 23.4922\n",
      "Epoch 581/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 23.1412 - mae: 23.1412 - val_loss: 23.3821 - val_mae: 23.3821\n",
      "Epoch 582/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 23.3547 - mae: 23.3547 - val_loss: 23.3434 - val_mae: 23.3434\n",
      "Epoch 583/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 23.0921 - mae: 23.0921 - val_loss: 24.0377 - val_mae: 24.0377\n",
      "Epoch 584/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 23.4477 - mae: 23.4477 - val_loss: 23.3145 - val_mae: 23.3145\n",
      "Epoch 585/1000\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 23.2104 - mae: 23.2104 - val_loss: 23.5069 - val_mae: 23.5069\n",
      "Epoch 586/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 23.5929 - mae: 23.5929 - val_loss: 23.9425 - val_mae: 23.9425\n",
      "Epoch 587/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 23.3838 - mae: 23.3838 - val_loss: 23.7392 - val_mae: 23.7392\n",
      "Epoch 588/1000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 23.2645 - mae: 23.2645 - val_loss: 23.5118 - val_mae: 23.5118\n",
      "Epoch 589/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 23.6021 - mae: 23.6021 - val_loss: 23.3077 - val_mae: 23.3077\n",
      "Epoch 590/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 23.1155 - mae: 23.1155 - val_loss: 23.9787 - val_mae: 23.9787\n",
      "Epoch 591/1000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 23.4079 - mae: 23.4079 - val_loss: 23.2964 - val_mae: 23.2964\n",
      "Epoch 592/1000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 23.1367 - mae: 23.1367 - val_loss: 23.3855 - val_mae: 23.3855\n",
      "Epoch 593/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 23.3841 - mae: 23.3841 - val_loss: 23.7999 - val_mae: 23.7999\n",
      "Epoch 594/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 23.3043 - mae: 23.3043 - val_loss: 23.4746 - val_mae: 23.4746\n",
      "Epoch 595/1000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 23.1360 - mae: 23.1360 - val_loss: 23.3181 - val_mae: 23.3181\n",
      "Epoch 596/1000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 23.2286 - mae: 23.2286 - val_loss: 23.2869 - val_mae: 23.2869\n",
      "Epoch 597/1000\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 23.1620 - mae: 23.1620 - val_loss: 23.6005 - val_mae: 23.6005\n",
      "Epoch 598/1000\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 23.1839 - mae: 23.1839 - val_loss: 23.5864 - val_mae: 23.5864\n",
      "Epoch 599/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 23.1779 - mae: 23.1779 - val_loss: 23.2844 - val_mae: 23.2844\n",
      "Epoch 600/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 23.1407 - mae: 23.1407 - val_loss: 23.3014 - val_mae: 23.3014\n",
      "Epoch 601/1000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 23.2073 - mae: 23.2073 - val_loss: 23.4529 - val_mae: 23.4529\n",
      "Epoch 602/1000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 23.1293 - mae: 23.1293 - val_loss: 23.4919 - val_mae: 23.4919\n",
      "Epoch 603/1000\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 23.1434 - mae: 23.1434 - val_loss: 23.2838 - val_mae: 23.2838\n",
      "Epoch 604/1000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 23.1291 - mae: 23.1291 - val_loss: 23.2832 - val_mae: 23.2832\n",
      "Epoch 605/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 23.1275 - mae: 23.1275 - val_loss: 23.5217 - val_mae: 23.5217\n",
      "Epoch 606/1000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 23.1547 - mae: 23.1547 - val_loss: 23.3983 - val_mae: 23.3983\n",
      "Epoch 607/1000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 23.1053 - mae: 23.1053 - val_loss: 23.2768 - val_mae: 23.2768\n",
      "Epoch 608/1000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 23.1740 - mae: 23.1740 - val_loss: 23.2809 - val_mae: 23.2809\n",
      "Epoch 609/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 23.1207 - mae: 23.1207 - val_loss: 23.6436 - val_mae: 23.6436\n",
      "Epoch 610/1000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 23.2135 - mae: 23.2135 - val_loss: 23.3049 - val_mae: 23.3049\n",
      "Epoch 611/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 23.0801 - mae: 23.0801 - val_loss: 23.2729 - val_mae: 23.2729\n",
      "Epoch 612/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 23.1315 - mae: 23.1315 - val_loss: 23.3017 - val_mae: 23.3017\n",
      "Epoch 613/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 23.0797 - mae: 23.0797 - val_loss: 23.5396 - val_mae: 23.5396\n",
      "Epoch 614/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 23.1623 - mae: 23.1623 - val_loss: 23.3173 - val_mae: 23.3173\n",
      "Epoch 615/1000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 23.0791 - mae: 23.0791 - val_loss: 23.2744 - val_mae: 23.2744\n",
      "Epoch 616/1000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 23.1126 - mae: 23.1126 - val_loss: 23.2947 - val_mae: 23.2947\n",
      "Epoch 617/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 23.0797 - mae: 23.0797 - val_loss: 23.3941 - val_mae: 23.3941\n",
      "Epoch 618/1000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 23.1085 - mae: 23.1085 - val_loss: 23.3139 - val_mae: 23.3139\n",
      "Epoch 619/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 23.0780 - mae: 23.0780 - val_loss: 23.2786 - val_mae: 23.2786\n",
      "Epoch 620/1000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 23.0944 - mae: 23.0944 - val_loss: 23.2786 - val_mae: 23.2786\n",
      "Epoch 621/1000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 23.0926 - mae: 23.0926 - val_loss: 23.3261 - val_mae: 23.3261\n",
      "Epoch 622/1000\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 23.0793 - mae: 23.0793 - val_loss: 23.3299 - val_mae: 23.3299\n",
      "Epoch 623/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 23.0801 - mae: 23.0801 - val_loss: 23.2614 - val_mae: 23.2614\n",
      "Epoch 624/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 23.1187 - mae: 23.1187 - val_loss: 23.3146 - val_mae: 23.3146\n",
      "Epoch 625/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 23.0771 - mae: 23.0771 - val_loss: 23.4074 - val_mae: 23.4074\n",
      "Epoch 626/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 23.1145 - mae: 23.1145 - val_loss: 23.2903 - val_mae: 23.2903\n",
      "Epoch 627/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 23.0722 - mae: 23.0722 - val_loss: 23.2537 - val_mae: 23.2537\n",
      "Epoch 628/1000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 23.1295 - mae: 23.1295 - val_loss: 23.3143 - val_mae: 23.3143\n",
      "Epoch 629/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 23.0763 - mae: 23.0763 - val_loss: 23.5486 - val_mae: 23.5486\n",
      "Epoch 630/1000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 23.1710 - mae: 23.1710 - val_loss: 23.2714 - val_mae: 23.2714\n",
      "Epoch 631/1000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 23.0825 - mae: 23.0825 - val_loss: 23.2491 - val_mae: 23.2491\n",
      "Epoch 632/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 23.1314 - mae: 23.1314 - val_loss: 23.4688 - val_mae: 23.4688\n",
      "Epoch 633/1000\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 23.1395 - mae: 23.1395 - val_loss: 23.3931 - val_mae: 23.3931\n",
      "Epoch 634/1000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 23.1100 - mae: 23.1100 - val_loss: 23.2480 - val_mae: 23.2480\n",
      "Epoch 635/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 23.1246 - mae: 23.1246 - val_loss: 23.2763 - val_mae: 23.2763\n",
      "Epoch 636/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 23.0699 - mae: 23.0699 - val_loss: 23.5493 - val_mae: 23.5493\n",
      "Epoch 637/1000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 23.1730 - mae: 23.1730 - val_loss: 23.2761 - val_mae: 23.2761\n",
      "Epoch 638/1000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 23.0679 - mae: 23.0679 - val_loss: 23.2433 - val_mae: 23.2433\n",
      "Epoch 639/1000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 23.1287 - mae: 23.1287 - val_loss: 23.3684 - val_mae: 23.3684\n",
      "Epoch 640/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 23.1012 - mae: 23.1012 - val_loss: 23.3056 - val_mae: 23.3056\n",
      "Epoch 641/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 23.0747 - mae: 23.0747 - val_loss: 23.2493 - val_mae: 23.2493\n",
      "Epoch 642/1000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 23.0992 - mae: 23.0992 - val_loss: 23.2506 - val_mae: 23.2506\n",
      "Epoch 643/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 23.0945 - mae: 23.0945 - val_loss: 23.3296 - val_mae: 23.3296\n",
      "Epoch 644/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 23.0859 - mae: 23.0859 - val_loss: 23.2806 - val_mae: 23.2806\n",
      "Epoch 645/1000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 23.0680 - mae: 23.0680 - val_loss: 23.2602 - val_mae: 23.2602\n",
      "Epoch 646/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 23.0730 - mae: 23.0730 - val_loss: 23.2648 - val_mae: 23.2648\n",
      "Epoch 647/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 23.0669 - mae: 23.0669 - val_loss: 23.3204 - val_mae: 23.3204\n",
      "Epoch 648/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 23.0825 - mae: 23.0825 - val_loss: 23.2606 - val_mae: 23.2606\n",
      "Epoch 649/1000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 23.0679 - mae: 23.0679 - val_loss: 23.2520 - val_mae: 23.2520\n",
      "Epoch 650/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 23.0776 - mae: 23.0776 - val_loss: 23.2617 - val_mae: 23.2617\n",
      "Epoch 651/1000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 23.0649 - mae: 23.0649 - val_loss: 23.3759 - val_mae: 23.3759\n",
      "Epoch 652/1000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 23.1046 - mae: 23.1046 - val_loss: 23.2719 - val_mae: 23.2719\n",
      "Epoch 653/1000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 23.0643 - mae: 23.0643 - val_loss: 23.2415 - val_mae: 23.2415\n",
      "Epoch 654/1000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 23.0890 - mae: 23.0890 - val_loss: 23.2507 - val_mae: 23.2507\n",
      "Epoch 655/1000\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 23.0706 - mae: 23.0706 - val_loss: 23.3415 - val_mae: 23.3415\n",
      "Epoch 656/1000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 23.0923 - mae: 23.0923 - val_loss: 23.2730 - val_mae: 23.2730\n",
      "Epoch 657/1000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 23.0651 - mae: 23.0651 - val_loss: 23.2459 - val_mae: 23.2459\n",
      "Epoch 658/1000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 23.0718 - mae: 23.0718 - val_loss: 23.2469 - val_mae: 23.2469\n",
      "Epoch 659/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 23.0686 - mae: 23.0686 - val_loss: 23.3342 - val_mae: 23.3342\n",
      "Epoch 660/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 23.0899 - mae: 23.0899 - val_loss: 23.2625 - val_mae: 23.2625\n",
      "Epoch 661/1000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 23.0602 - mae: 23.0602 - val_loss: 23.2269 - val_mae: 23.2269\n",
      "Epoch 662/1000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 23.1067 - mae: 23.1067 - val_loss: 23.3454 - val_mae: 23.3454\n",
      "Epoch 663/1000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 23.0941 - mae: 23.0941 - val_loss: 23.3367 - val_mae: 23.3367\n",
      "Epoch 664/1000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 23.0910 - mae: 23.0910 - val_loss: 23.2232 - val_mae: 23.2232\n",
      "Epoch 665/1000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 23.1242 - mae: 23.1242 - val_loss: 23.3082 - val_mae: 23.3082\n",
      "Epoch 666/1000\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 23.0812 - mae: 23.0812 - val_loss: 23.3425 - val_mae: 23.3425\n",
      "Epoch 667/1000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 23.0930 - mae: 23.0930 - val_loss: 23.2290 - val_mae: 23.2290\n",
      "Epoch 668/1000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 23.0842 - mae: 23.0842 - val_loss: 23.2485 - val_mae: 23.2485\n",
      "Epoch 669/1000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 23.0555 - mae: 23.0555 - val_loss: 23.2673 - val_mae: 23.2673\n",
      "Epoch 670/1000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 23.0630 - mae: 23.0630 - val_loss: 23.2294 - val_mae: 23.2294\n",
      "Epoch 671/1000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 23.0776 - mae: 23.0776 - val_loss: 23.2557 - val_mae: 23.2557\n",
      "Epoch 672/1000\n",
      "1/1 [==============================] - 0s 161ms/step - loss: 23.0571 - mae: 23.0571 - val_loss: 23.2702 - val_mae: 23.2702\n",
      "Epoch 673/1000\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 23.0652 - mae: 23.0652 - val_loss: 23.2197 - val_mae: 23.2197\n",
      "Epoch 674/1000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 23.0986 - mae: 23.0986 - val_loss: 23.4100 - val_mae: 23.4100\n",
      "Epoch 675/1000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 23.1174 - mae: 23.1174 - val_loss: 23.3662 - val_mae: 23.3662\n",
      "Epoch 676/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 23.1011 - mae: 23.1011 - val_loss: 23.2184 - val_mae: 23.2184\n",
      "Epoch 677/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 23.0971 - mae: 23.0971 - val_loss: 23.2926 - val_mae: 23.2926\n",
      "Epoch 678/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 23.0760 - mae: 23.0760 - val_loss: 23.2549 - val_mae: 23.2549\n",
      "Epoch 679/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 23.0563 - mae: 23.0563 - val_loss: 23.2378 - val_mae: 23.2378\n",
      "Epoch 680/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 23.0547 - mae: 23.0547 - val_loss: 23.2377 - val_mae: 23.2377\n",
      "Epoch 681/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 23.0541 - mae: 23.0541 - val_loss: 23.2538 - val_mae: 23.2538\n",
      "Epoch 682/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 23.0555 - mae: 23.0555 - val_loss: 23.2542 - val_mae: 23.2542\n",
      "Epoch 683/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 23.0557 - mae: 23.0557 - val_loss: 23.2421 - val_mae: 23.2421\n",
      "Epoch 684/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 23.0502 - mae: 23.0502 - val_loss: 23.2387 - val_mae: 23.2387\n",
      "Epoch 685/1000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 23.0503 - mae: 23.0503 - val_loss: 23.2511 - val_mae: 23.2511\n",
      "Epoch 686/1000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 23.0540 - mae: 23.0540 - val_loss: 23.2457 - val_mae: 23.2457\n",
      "Epoch 687/1000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 23.0510 - mae: 23.0510 - val_loss: 23.2267 - val_mae: 23.2267\n",
      "Epoch 688/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 23.0584 - mae: 23.0584 - val_loss: 23.3175 - val_mae: 23.3175\n",
      "Epoch 689/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 23.0820 - mae: 23.0820 - val_loss: 23.2289 - val_mae: 23.2289\n",
      "Epoch 690/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 23.0527 - mae: 23.0527 - val_loss: 23.2236 - val_mae: 23.2236\n",
      "Epoch 691/1000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 23.0591 - mae: 23.0591 - val_loss: 23.3414 - val_mae: 23.3414\n",
      "Epoch 692/1000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 23.0907 - mae: 23.0907 - val_loss: 23.2440 - val_mae: 23.2440\n",
      "Epoch 693/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 23.0502 - mae: 23.0502 - val_loss: 23.2072 - val_mae: 23.2072\n",
      "Epoch 694/1000\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 23.1015 - mae: 23.1015 - val_loss: 23.3785 - val_mae: 23.3785\n",
      "Epoch 695/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 23.1041 - mae: 23.1041 - val_loss: 23.3805 - val_mae: 23.3805\n",
      "Epoch 696/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 23.1048 - mae: 23.1048 - val_loss: 23.2107 - val_mae: 23.2107\n",
      "Epoch 697/1000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 23.0771 - mae: 23.0771 - val_loss: 23.2453 - val_mae: 23.2453\n",
      "Epoch 698/1000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 23.0511 - mae: 23.0511 - val_loss: 23.2361 - val_mae: 23.2361\n",
      "Epoch 699/1000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 23.0458 - mae: 23.0458 - val_loss: 23.2149 - val_mae: 23.2149\n",
      "Epoch 700/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 23.0607 - mae: 23.0607 - val_loss: 23.2644 - val_mae: 23.2644\n",
      "Epoch 701/1000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 23.0639 - mae: 23.0639 - val_loss: 23.2405 - val_mae: 23.2405\n",
      "Epoch 702/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 23.0482 - mae: 23.0482 - val_loss: 23.2084 - val_mae: 23.2084\n",
      "Epoch 703/1000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 23.0713 - mae: 23.0713 - val_loss: 23.3866 - val_mae: 23.3866\n",
      "Epoch 704/1000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 23.1063 - mae: 23.1063 - val_loss: 23.3671 - val_mae: 23.3671\n",
      "Epoch 705/1000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 23.0991 - mae: 23.0991 - val_loss: 23.2094 - val_mae: 23.2094\n",
      "Epoch 706/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 23.1365 - mae: 23.1365 - val_loss: 23.3726 - val_mae: 23.3726\n",
      "Epoch 707/1000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 23.1009 - mae: 23.1009 - val_loss: 23.3782 - val_mae: 23.3782\n",
      "Epoch 708/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 23.1028 - mae: 23.1028 - val_loss: 23.2023 - val_mae: 23.2023\n",
      "Epoch 709/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 23.0809 - mae: 23.0809 - val_loss: 23.2737 - val_mae: 23.2737\n",
      "Epoch 710/1000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 23.0669 - mae: 23.0669 - val_loss: 23.2535 - val_mae: 23.2535\n",
      "Epoch 711/1000\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 23.0570 - mae: 23.0570 - val_loss: 23.2044 - val_mae: 23.2044\n",
      "Epoch 712/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 23.1189 - mae: 23.1189 - val_loss: 23.4064 - val_mae: 23.4064\n",
      "Epoch 713/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 23.1144 - mae: 23.1144 - val_loss: 23.3132 - val_mae: 23.3132\n",
      "Epoch 714/1000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 23.0776 - mae: 23.0776 - val_loss: 23.2081 - val_mae: 23.2081\n",
      "Epoch 715/1000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 23.1439 - mae: 23.1439 - val_loss: 23.2551 - val_mae: 23.2551\n",
      "Epoch 716/1000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 23.0568 - mae: 23.0568 - val_loss: 23.3534 - val_mae: 23.3534\n",
      "Epoch 717/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 23.0916 - mae: 23.0916 - val_loss: 23.2152 - val_mae: 23.2152\n",
      "Epoch 718/1000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 23.0428 - mae: 23.0428 - val_loss: 23.2033 - val_mae: 23.2033\n",
      "Epoch 719/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 23.1223 - mae: 23.1223 - val_loss: 23.6258 - val_mae: 23.6258\n",
      "Epoch 720/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 23.2275 - mae: 23.2275 - val_loss: 23.2280 - val_mae: 23.2280\n",
      "Epoch 721/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 23.0390 - mae: 23.0390 - val_loss: 23.3478 - val_mae: 23.3478\n",
      "Epoch 722/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 23.3805 - mae: 23.3805 - val_loss: 23.9510 - val_mae: 23.9510\n",
      "Epoch 723/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 23.4045 - mae: 23.4045 - val_loss: 23.2297 - val_mae: 23.2297\n",
      "Epoch 724/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 23.0396 - mae: 23.0396 - val_loss: 23.3507 - val_mae: 23.3507\n",
      "Epoch 725/1000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 23.3879 - mae: 23.3879 - val_loss: 23.6592 - val_mae: 23.6592\n",
      "Epoch 726/1000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 23.2457 - mae: 23.2457 - val_loss: 23.4448 - val_mae: 23.4448\n",
      "Epoch 727/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 23.1307 - mae: 23.1307 - val_loss: 23.2790 - val_mae: 23.2790\n",
      "Epoch 728/1000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 23.2742 - mae: 23.2742 - val_loss: 23.2058 - val_mae: 23.2058\n",
      "Epoch 729/1000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 23.1535 - mae: 23.1535 - val_loss: 24.3109 - val_mae: 24.3109\n",
      "Epoch 730/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 23.6589 - mae: 23.6589 - val_loss: 23.9063 - val_mae: 23.9063\n",
      "Epoch 731/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 24.1797 - mae: 24.1797 - val_loss: 23.1961 - val_mae: 23.1961\n",
      "Epoch 732/1000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 23.1048 - mae: 23.1048 - val_loss: 25.9612 - val_mae: 25.9612\n",
      "Epoch 733/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 25.1190 - mae: 25.1190 - val_loss: 26.9850 - val_mae: 26.9850\n",
      "Epoch 734/1000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 27.3863 - mae: 27.3863 - val_loss: 26.3457 - val_mae: 26.3457\n",
      "Epoch 735/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 26.7644 - mae: 26.7644 - val_loss: 26.4073 - val_mae: 26.4073\n",
      "Epoch 736/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 25.6153 - mae: 25.6153 - val_loss: 23.2561 - val_mae: 23.2561\n",
      "Epoch 737/1000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 23.2473 - mae: 23.2473 - val_loss: 24.1361 - val_mae: 24.1361\n",
      "Epoch 738/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 24.3996 - mae: 24.3996 - val_loss: 24.0890 - val_mae: 24.0890\n",
      "Epoch 739/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 23.4851 - mae: 23.4851 - val_loss: 23.5163 - val_mae: 23.5163\n",
      "Epoch 740/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 23.1548 - mae: 23.1548 - val_loss: 23.2857 - val_mae: 23.2857\n",
      "Epoch 741/1000\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 23.2781 - mae: 23.2781 - val_loss: 23.2298 - val_mae: 23.2298\n",
      "Epoch 742/1000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 23.1904 - mae: 23.1904 - val_loss: 23.8728 - val_mae: 23.8728\n",
      "Epoch 743/1000\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 23.3529 - mae: 23.3529 - val_loss: 23.2274 - val_mae: 23.2274\n",
      "Epoch 744/1000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 23.0330 - mae: 23.0330 - val_loss: 23.3289 - val_mae: 23.3289\n",
      "Epoch 745/1000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 23.3457 - mae: 23.3457 - val_loss: 23.8891 - val_mae: 23.8891\n",
      "Epoch 746/1000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 23.3607 - mae: 23.3607 - val_loss: 23.2405 - val_mae: 23.2405\n",
      "Epoch 747/1000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 23.0366 - mae: 23.0366 - val_loss: 23.3182 - val_mae: 23.3182\n",
      "Epoch 748/1000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 23.3241 - mae: 23.3241 - val_loss: 23.7701 - val_mae: 23.7701\n",
      "Epoch 749/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 23.2953 - mae: 23.2953 - val_loss: 23.3202 - val_mae: 23.3202\n",
      "Epoch 750/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 23.0669 - mae: 23.0669 - val_loss: 23.3237 - val_mae: 23.3237\n",
      "Epoch 751/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 23.3361 - mae: 23.3361 - val_loss: 23.4802 - val_mae: 23.4802\n",
      "Epoch 752/1000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 23.1318 - mae: 23.1318 - val_loss: 23.8985 - val_mae: 23.8985\n",
      "Epoch 753/1000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 23.3645 - mae: 23.3645 - val_loss: 23.4572 - val_mae: 23.4572\n",
      "Epoch 754/1000\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 23.5737 - mae: 23.5737 - val_loss: 23.2155 - val_mae: 23.2155\n",
      "Epoch 755/1000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 23.0454 - mae: 23.0454 - val_loss: 24.1605 - val_mae: 24.1605\n",
      "Epoch 756/1000\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 23.5332 - mae: 23.5332 - val_loss: 23.6076 - val_mae: 23.6076\n",
      "Epoch 757/1000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 23.7936 - mae: 23.7936 - val_loss: 23.2392 - val_mae: 23.2392\n",
      "Epoch 758/1000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 23.0335 - mae: 23.0335 - val_loss: 24.4188 - val_mae: 24.4188\n",
      "Epoch 759/1000\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 23.7471 - mae: 23.7471 - val_loss: 24.6648 - val_mae: 24.6648\n",
      "Epoch 760/1000\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 24.9432 - mae: 24.9432 - val_loss: 23.2478 - val_mae: 23.2478\n",
      "Epoch 761/1000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 23.2192 - mae: 23.2192 - val_loss: 25.6143 - val_mae: 25.6143\n",
      "Epoch 762/1000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 24.7613 - mae: 24.7613 - val_loss: 24.9683 - val_mae: 24.9683\n",
      "Epoch 763/1000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 25.2657 - mae: 25.2657 - val_loss: 23.8573 - val_mae: 23.8573\n",
      "Epoch 764/1000\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 24.1449 - mae: 24.1449 - val_loss: 26.9331 - val_mae: 26.9331\n",
      "Epoch 765/1000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 26.2136 - mae: 26.2136 - val_loss: 23.8551 - val_mae: 23.8551\n",
      "Epoch 766/1000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 24.1436 - mae: 24.1436 - val_loss: 24.1677 - val_mae: 24.1677\n",
      "Epoch 767/1000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 24.4379 - mae: 24.4379 - val_loss: 25.2801 - val_mae: 25.2801\n",
      "Epoch 768/1000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 24.4633 - mae: 24.4633 - val_loss: 23.2106 - val_mae: 23.2106\n",
      "Epoch 769/1000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 23.0546 - mae: 23.0546 - val_loss: 23.7357 - val_mae: 23.7357\n",
      "Epoch 770/1000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 23.9993 - mae: 23.9993 - val_loss: 23.7627 - val_mae: 23.7627\n",
      "Epoch 771/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 23.2843 - mae: 23.2843 - val_loss: 24.2615 - val_mae: 24.2615\n",
      "Epoch 772/1000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 23.6217 - mae: 23.6217 - val_loss: 25.0512 - val_mae: 25.0512\n",
      "Epoch 773/1000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 25.3584 - mae: 25.3584 - val_loss: 23.5227 - val_mae: 23.5227\n",
      "Epoch 774/1000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 23.6631 - mae: 23.6631 - val_loss: 27.9363 - val_mae: 27.9363\n",
      "Epoch 775/1000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 27.1551 - mae: 27.1551 - val_loss: 23.8236 - val_mae: 23.8236\n",
      "Epoch 776/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 24.1147 - mae: 24.1147 - val_loss: 24.5084 - val_mae: 24.5084\n",
      "Epoch 777/1000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 24.7865 - mae: 24.7865 - val_loss: 24.9464 - val_mae: 24.9464\n",
      "Epoch 778/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 24.1849 - mae: 24.1849 - val_loss: 23.2723 - val_mae: 23.2723\n",
      "Epoch 779/1000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 23.0337 - mae: 23.0337 - val_loss: 23.7467 - val_mae: 23.7467\n",
      "Epoch 780/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 24.0154 - mae: 24.0154 - val_loss: 23.2881 - val_mae: 23.2881\n",
      "Epoch 781/1000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 23.0396 - mae: 23.0396 - val_loss: 24.2864 - val_mae: 24.2864\n",
      "Epoch 782/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 23.6423 - mae: 23.6423 - val_loss: 23.7372 - val_mae: 23.7372\n",
      "Epoch 783/1000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 23.9999 - mae: 23.9999 - val_loss: 23.2856 - val_mae: 23.2856\n",
      "Epoch 784/1000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 23.2707 - mae: 23.2707 - val_loss: 24.8641 - val_mae: 24.8641\n",
      "Epoch 785/1000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 24.1199 - mae: 24.1199 - val_loss: 23.4347 - val_mae: 23.4347\n",
      "Epoch 786/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 23.5437 - mae: 23.5437 - val_loss: 23.3338 - val_mae: 23.3338\n",
      "Epoch 787/1000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 23.3622 - mae: 23.3622 - val_loss: 25.1732 - val_mae: 25.1732\n",
      "Epoch 788/1000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 24.3796 - mae: 24.3796 - val_loss: 23.5581 - val_mae: 23.5581\n",
      "Epoch 789/1000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 23.7159 - mae: 23.7159 - val_loss: 23.4155 - val_mae: 23.4155\n",
      "Epoch 790/1000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 23.5136 - mae: 23.5136 - val_loss: 25.1941 - val_mae: 25.1941\n",
      "Epoch 791/1000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 24.3976 - mae: 24.3976 - val_loss: 23.3756 - val_mae: 23.3756\n",
      "Epoch 792/1000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 23.4510 - mae: 23.4510 - val_loss: 23.3720 - val_mae: 23.3720\n",
      "Epoch 793/1000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 23.4433 - mae: 23.4433 - val_loss: 24.7718 - val_mae: 24.7718\n",
      "Epoch 794/1000\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 24.0453 - mae: 24.0453 - val_loss: 23.2985 - val_mae: 23.2985\n",
      "Epoch 795/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 23.2971 - mae: 23.2971 - val_loss: 23.4012 - val_mae: 23.4012\n",
      "Epoch 796/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 23.4929 - mae: 23.4929 - val_loss: 24.2955 - val_mae: 24.2955\n",
      "Epoch 797/1000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 23.6497 - mae: 23.6497 - val_loss: 23.2038 - val_mae: 23.2038\n",
      "Epoch 798/1000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 23.0773 - mae: 23.0773 - val_loss: 23.3824 - val_mae: 23.3824\n",
      "Epoch 799/1000\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 23.4650 - mae: 23.4650 - val_loss: 23.6335 - val_mae: 23.6335\n",
      "Epoch 800/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 23.2070 - mae: 23.2070 - val_loss: 23.8919 - val_mae: 23.8919\n",
      "Epoch 801/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 23.3512 - mae: 23.3512 - val_loss: 23.4490 - val_mae: 23.4490\n",
      "Epoch 802/1000\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 23.5697 - mae: 23.5697 - val_loss: 23.2180 - val_mae: 23.2180\n",
      "Epoch 803/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 23.1499 - mae: 23.1499 - val_loss: 24.2857 - val_mae: 24.2857\n",
      "Epoch 804/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 23.6410 - mae: 23.6410 - val_loss: 23.3088 - val_mae: 23.3088\n",
      "Epoch 805/1000\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 23.3194 - mae: 23.3194 - val_loss: 23.2158 - val_mae: 23.2158\n",
      "Epoch 806/1000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 23.1492 - mae: 23.1492 - val_loss: 23.9931 - val_mae: 23.9931\n",
      "Epoch 807/1000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 23.4114 - mae: 23.4114 - val_loss: 23.2364 - val_mae: 23.2364\n",
      "Epoch 808/1000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 23.0223 - mae: 23.0223 - val_loss: 23.2811 - val_mae: 23.2811\n",
      "Epoch 809/1000\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 23.2733 - mae: 23.2733 - val_loss: 23.2233 - val_mae: 23.2233\n",
      "Epoch 810/1000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 23.0199 - mae: 23.0199 - val_loss: 23.6630 - val_mae: 23.6630\n",
      "Epoch 811/1000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 23.2299 - mae: 23.2299 - val_loss: 23.2231 - val_mae: 23.2231\n",
      "Epoch 812/1000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 23.0180 - mae: 23.0180 - val_loss: 23.2194 - val_mae: 23.2194\n",
      "Epoch 813/1000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 23.1653 - mae: 23.1653 - val_loss: 23.2821 - val_mae: 23.2821\n",
      "Epoch 814/1000\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 23.0388 - mae: 23.0388 - val_loss: 23.3368 - val_mae: 23.3368\n",
      "Epoch 815/1000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 23.0599 - mae: 23.0599 - val_loss: 23.2179 - val_mae: 23.2179\n",
      "Epoch 816/1000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 23.0181 - mae: 23.0181 - val_loss: 23.1998 - val_mae: 23.1998\n",
      "Epoch 817/1000\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 23.0406 - mae: 23.0406 - val_loss: 23.2123 - val_mae: 23.2123\n",
      "Epoch 818/1000\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 23.0202 - mae: 23.0202 - val_loss: 23.3176 - val_mae: 23.3176\n",
      "Epoch 819/1000\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 23.0530 - mae: 23.0530 - val_loss: 23.2280 - val_mae: 23.2280\n",
      "Epoch 820/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 23.0189 - mae: 23.0189 - val_loss: 23.2020 - val_mae: 23.2020\n",
      "Epoch 821/1000\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 23.0291 - mae: 23.0291 - val_loss: 23.2021 - val_mae: 23.2021\n",
      "Epoch 822/1000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 23.0274 - mae: 23.0274 - val_loss: 23.2303 - val_mae: 23.2303\n",
      "Epoch 823/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 23.0192 - mae: 23.0192 - val_loss: 23.3726 - val_mae: 23.3726\n",
      "Epoch 824/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 23.0736 - mae: 23.0736 - val_loss: 23.2046 - val_mae: 23.2046\n",
      "Epoch 825/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 23.0188 - mae: 23.0188 - val_loss: 23.1942 - val_mae: 23.1942\n",
      "Epoch 826/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 23.0323 - mae: 23.0323 - val_loss: 23.3447 - val_mae: 23.3447\n",
      "Epoch 827/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 23.0636 - mae: 23.0636 - val_loss: 23.2148 - val_mae: 23.2148\n",
      "Epoch 828/1000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 23.0129 - mae: 23.0129 - val_loss: 23.1869 - val_mae: 23.1869\n",
      "Epoch 829/1000\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 23.0403 - mae: 23.0403 - val_loss: 23.1994 - val_mae: 23.1994\n",
      "Epoch 830/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 23.0164 - mae: 23.0164 - val_loss: 23.4291 - val_mae: 23.4291\n",
      "Epoch 831/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 23.1004 - mae: 23.1004 - val_loss: 23.2018 - val_mae: 23.2018\n",
      "Epoch 832/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 23.0122 - mae: 23.0122 - val_loss: 23.1847 - val_mae: 23.1847\n",
      "Epoch 833/1000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 23.0352 - mae: 23.0352 - val_loss: 23.2064 - val_mae: 23.2064\n",
      "Epoch 834/1000\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 23.0095 - mae: 23.0095 - val_loss: 23.2780 - val_mae: 23.2780\n",
      "Epoch 835/1000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 23.0400 - mae: 23.0400 - val_loss: 23.1771 - val_mae: 23.1771\n",
      "Epoch 836/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 23.0461 - mae: 23.0461 - val_loss: 23.2039 - val_mae: 23.2039\n",
      "Epoch 837/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 23.0086 - mae: 23.0086 - val_loss: 23.2992 - val_mae: 23.2992\n",
      "Epoch 838/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 23.0479 - mae: 23.0479 - val_loss: 23.1849 - val_mae: 23.1849\n",
      "Epoch 839/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 23.0206 - mae: 23.0206 - val_loss: 23.1925 - val_mae: 23.1925\n",
      "Epoch 840/1000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 23.0100 - mae: 23.0100 - val_loss: 23.2375 - val_mae: 23.2375\n",
      "Epoch 841/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 23.0276 - mae: 23.0276 - val_loss: 23.1994 - val_mae: 23.1994\n",
      "Epoch 842/1000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 23.0067 - mae: 23.0067 - val_loss: 23.1742 - val_mae: 23.1742\n",
      "Epoch 843/1000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 23.0354 - mae: 23.0354 - val_loss: 23.2176 - val_mae: 23.2176\n",
      "Epoch 844/1000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 23.0169 - mae: 23.0169 - val_loss: 23.1959 - val_mae: 23.1959\n",
      "Epoch 845/1000\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 23.0049 - mae: 23.0049 - val_loss: 23.1766 - val_mae: 23.1766\n",
      "Epoch 846/1000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 23.0234 - mae: 23.0234 - val_loss: 23.1979 - val_mae: 23.1979\n",
      "Epoch 847/1000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 23.0062 - mae: 23.0062 - val_loss: 23.2318 - val_mae: 23.2318\n",
      "Epoch 848/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 23.0259 - mae: 23.0259 - val_loss: 23.1829 - val_mae: 23.1829\n",
      "Epoch 849/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 23.0084 - mae: 23.0084 - val_loss: 23.1731 - val_mae: 23.1731\n",
      "Epoch 850/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 23.0231 - mae: 23.0231 - val_loss: 23.2219 - val_mae: 23.2219\n",
      "Epoch 851/1000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 23.0211 - mae: 23.0211 - val_loss: 23.1951 - val_mae: 23.1951\n",
      "Epoch 852/1000\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 23.0049 - mae: 23.0049 - val_loss: 23.1751 - val_mae: 23.1751\n",
      "Epoch 853/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 23.0135 - mae: 23.0135 - val_loss: 23.2172 - val_mae: 23.2172\n",
      "Epoch 854/1000\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 23.0188 - mae: 23.0188 - val_loss: 23.1834 - val_mae: 23.1834\n",
      "Epoch 855/1000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 23.0024 - mae: 23.0024 - val_loss: 23.1838 - val_mae: 23.1838\n",
      "Epoch 856/1000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 23.0012 - mae: 23.0012 - val_loss: 23.2210 - val_mae: 23.2210\n",
      "Epoch 857/1000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 23.0217 - mae: 23.0217 - val_loss: 23.1768 - val_mae: 23.1768\n",
      "Epoch 858/1000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 23.0043 - mae: 23.0043 - val_loss: 23.1717 - val_mae: 23.1717\n",
      "Epoch 859/1000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 23.0091 - mae: 23.0091 - val_loss: 23.2679 - val_mae: 23.2679\n",
      "Epoch 860/1000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 23.0368 - mae: 23.0368 - val_loss: 23.1893 - val_mae: 23.1893\n",
      "Epoch 861/1000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 23.0023 - mae: 23.0023 - val_loss: 23.1603 - val_mae: 23.1603\n",
      "Epoch 862/1000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 23.0303 - mae: 23.0303 - val_loss: 23.2624 - val_mae: 23.2624\n",
      "Epoch 863/1000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 23.0348 - mae: 23.0348 - val_loss: 23.2107 - val_mae: 23.2107\n",
      "Epoch 864/1000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 23.0171 - mae: 23.0171 - val_loss: 23.1582 - val_mae: 23.1582\n",
      "Epoch 865/1000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 23.0783 - mae: 23.0783 - val_loss: 23.2992 - val_mae: 23.2992\n",
      "Epoch 866/1000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 23.0480 - mae: 23.0480 - val_loss: 23.3439 - val_mae: 23.3439\n",
      "Epoch 867/1000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 23.0660 - mae: 23.0660 - val_loss: 23.1648 - val_mae: 23.1648\n",
      "Epoch 868/1000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 23.0078 - mae: 23.0078 - val_loss: 23.1516 - val_mae: 23.1516\n",
      "Epoch 869/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 23.0466 - mae: 23.0466 - val_loss: 23.4489 - val_mae: 23.4489\n",
      "Epoch 870/1000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 23.1149 - mae: 23.1149 - val_loss: 23.3503 - val_mae: 23.3503\n",
      "Epoch 871/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 23.0689 - mae: 23.0689 - val_loss: 23.1534 - val_mae: 23.1534\n",
      "Epoch 872/1000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 23.0664 - mae: 23.0664 - val_loss: 23.1738 - val_mae: 23.1738\n",
      "Epoch 873/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 22.9949 - mae: 22.9949 - val_loss: 23.2669 - val_mae: 23.2669\n",
      "Epoch 874/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 23.0353 - mae: 23.0353 - val_loss: 23.1745 - val_mae: 23.1745\n",
      "Epoch 875/1000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 22.9940 - mae: 22.9940 - val_loss: 23.1567 - val_mae: 23.1567\n",
      "Epoch 876/1000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 23.0142 - mae: 23.0142 - val_loss: 23.2123 - val_mae: 23.2123\n",
      "Epoch 877/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 23.0169 - mae: 23.0169 - val_loss: 23.1861 - val_mae: 23.1861\n",
      "Epoch 878/1000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 23.0003 - mae: 23.0003 - val_loss: 23.1570 - val_mae: 23.1570\n",
      "Epoch 879/1000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 23.0085 - mae: 23.0085 - val_loss: 23.1713 - val_mae: 23.1713\n",
      "Epoch 880/1000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 22.9924 - mae: 22.9924 - val_loss: 23.1897 - val_mae: 23.1897\n",
      "Epoch 881/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 23.0046 - mae: 23.0046 - val_loss: 23.1655 - val_mae: 23.1655\n",
      "Epoch 882/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 22.9935 - mae: 22.9935 - val_loss: 23.1579 - val_mae: 23.1579\n",
      "Epoch 883/1000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 23.0006 - mae: 23.0006 - val_loss: 23.2674 - val_mae: 23.2674\n",
      "Epoch 884/1000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 23.0348 - mae: 23.0348 - val_loss: 23.1728 - val_mae: 23.1728\n",
      "Epoch 885/1000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 22.9930 - mae: 22.9930 - val_loss: 23.1445 - val_mae: 23.1445\n",
      "Epoch 886/1000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 23.0335 - mae: 23.0335 - val_loss: 23.3247 - val_mae: 23.3247\n",
      "Epoch 887/1000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 23.0573 - mae: 23.0573 - val_loss: 23.2704 - val_mae: 23.2704\n",
      "Epoch 888/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 23.0357 - mae: 23.0357 - val_loss: 23.1544 - val_mae: 23.1544\n",
      "Epoch 889/1000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 23.1100 - mae: 23.1100 - val_loss: 23.1805 - val_mae: 23.1805\n",
      "Epoch 890/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 22.9991 - mae: 22.9991 - val_loss: 23.2957 - val_mae: 23.2957\n",
      "Epoch 891/1000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 23.0445 - mae: 23.0445 - val_loss: 23.1555 - val_mae: 23.1555\n",
      "Epoch 892/1000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 22.9931 - mae: 22.9931 - val_loss: 23.1486 - val_mae: 23.1486\n",
      "Epoch 893/1000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 23.0843 - mae: 23.0843 - val_loss: 23.4939 - val_mae: 23.4939\n",
      "Epoch 894/1000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 23.1405 - mae: 23.1405 - val_loss: 23.3134 - val_mae: 23.3134\n",
      "Epoch 895/1000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 23.0516 - mae: 23.0516 - val_loss: 23.2098 - val_mae: 23.2098\n",
      "Epoch 896/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 23.2111 - mae: 23.2111 - val_loss: 23.1492 - val_mae: 23.1492\n",
      "Epoch 897/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 22.9993 - mae: 22.9993 - val_loss: 23.4651 - val_mae: 23.4651\n",
      "Epoch 898/1000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 23.1237 - mae: 23.1237 - val_loss: 23.1744 - val_mae: 23.1744\n",
      "Epoch 899/1000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 22.9928 - mae: 22.9928 - val_loss: 23.1436 - val_mae: 23.1436\n",
      "Epoch 900/1000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 23.0671 - mae: 23.0671 - val_loss: 23.2485 - val_mae: 23.2485\n",
      "Epoch 901/1000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 23.0261 - mae: 23.0261 - val_loss: 23.5176 - val_mae: 23.5176\n",
      "Epoch 902/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 23.1515 - mae: 23.1515 - val_loss: 23.1637 - val_mae: 23.1637\n",
      "Epoch 903/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 23.1486 - mae: 23.1486 - val_loss: 23.1466 - val_mae: 23.1466\n",
      "Epoch 904/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 22.9974 - mae: 22.9974 - val_loss: 23.3656 - val_mae: 23.3656\n",
      "Epoch 905/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 23.0739 - mae: 23.0739 - val_loss: 23.2306 - val_mae: 23.2306\n",
      "Epoch 906/1000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 23.0201 - mae: 23.0201 - val_loss: 23.1528 - val_mae: 23.1528\n",
      "Epoch 907/1000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 22.9866 - mae: 22.9866 - val_loss: 23.1450 - val_mae: 23.1450\n",
      "Epoch 908/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 23.0873 - mae: 23.0873 - val_loss: 23.4920 - val_mae: 23.4920\n",
      "Epoch 909/1000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 23.1375 - mae: 23.1375 - val_loss: 23.1854 - val_mae: 23.1854\n",
      "Epoch 910/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 23.0011 - mae: 23.0011 - val_loss: 23.1559 - val_mae: 23.1559\n",
      "Epoch 911/1000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 23.1351 - mae: 23.1351 - val_loss: 23.1733 - val_mae: 23.1733\n",
      "Epoch 912/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 22.9927 - mae: 22.9927 - val_loss: 23.1916 - val_mae: 23.1916\n",
      "Epoch 913/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 23.0038 - mae: 23.0038 - val_loss: 23.1606 - val_mae: 23.1606\n",
      "Epoch 914/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 22.9833 - mae: 22.9833 - val_loss: 23.1448 - val_mae: 23.1448\n",
      "Epoch 915/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 23.0938 - mae: 23.0938 - val_loss: 23.3533 - val_mae: 23.3533\n",
      "Epoch 916/1000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 23.0657 - mae: 23.0657 - val_loss: 23.4063 - val_mae: 23.4063\n",
      "Epoch 917/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 23.0916 - mae: 23.0916 - val_loss: 23.1353 - val_mae: 23.1353\n",
      "Epoch 918/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 23.0454 - mae: 23.0454 - val_loss: 23.1538 - val_mae: 23.1538\n",
      "Epoch 919/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 22.9808 - mae: 22.9808 - val_loss: 23.1940 - val_mae: 23.1940\n",
      "Epoch 920/1000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 23.0031 - mae: 23.0031 - val_loss: 23.1788 - val_mae: 23.1788\n",
      "Epoch 921/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 22.9949 - mae: 22.9949 - val_loss: 23.1400 - val_mae: 23.1400\n",
      "Epoch 922/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 23.0742 - mae: 23.0742 - val_loss: 23.3202 - val_mae: 23.3202\n",
      "Epoch 923/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 23.0487 - mae: 23.0487 - val_loss: 23.3146 - val_mae: 23.3146\n",
      "Epoch 924/1000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 23.0459 - mae: 23.0459 - val_loss: 23.1418 - val_mae: 23.1418\n",
      "Epoch 925/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 23.0876 - mae: 23.0876 - val_loss: 23.1997 - val_mae: 23.1997\n",
      "Epoch 926/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 23.0037 - mae: 23.0037 - val_loss: 23.2633 - val_mae: 23.2633\n",
      "Epoch 927/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 23.0249 - mae: 23.0249 - val_loss: 23.1318 - val_mae: 23.1318\n",
      "Epoch 928/1000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 23.0380 - mae: 23.0380 - val_loss: 23.2649 - val_mae: 23.2649\n",
      "Epoch 929/1000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 23.0248 - mae: 23.0248 - val_loss: 23.1808 - val_mae: 23.1808\n",
      "Epoch 930/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 22.9934 - mae: 22.9934 - val_loss: 23.1418 - val_mae: 23.1418\n",
      "Epoch 931/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 23.0930 - mae: 23.0930 - val_loss: 23.3110 - val_mae: 23.3110\n",
      "Epoch 932/1000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 23.0418 - mae: 23.0418 - val_loss: 23.2763 - val_mae: 23.2763\n",
      "Epoch 933/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 23.0278 - mae: 23.0278 - val_loss: 23.1367 - val_mae: 23.1367\n",
      "Epoch 934/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 23.0665 - mae: 23.0665 - val_loss: 23.2981 - val_mae: 23.2981\n",
      "Epoch 935/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 23.0352 - mae: 23.0352 - val_loss: 23.3058 - val_mae: 23.3058\n",
      "Epoch 936/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 23.0381 - mae: 23.0381 - val_loss: 23.1328 - val_mae: 23.1328\n",
      "Epoch 937/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 23.0479 - mae: 23.0479 - val_loss: 23.1704 - val_mae: 23.1704\n",
      "Epoch 938/1000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 22.9828 - mae: 22.9828 - val_loss: 23.3339 - val_mae: 23.3339\n",
      "Epoch 939/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 23.0502 - mae: 23.0502 - val_loss: 23.1474 - val_mae: 23.1474\n",
      "Epoch 940/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 22.9800 - mae: 22.9800 - val_loss: 23.1306 - val_mae: 23.1306\n",
      "Epoch 941/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 23.0222 - mae: 23.0222 - val_loss: 23.3344 - val_mae: 23.3344\n",
      "Epoch 942/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 23.0497 - mae: 23.0497 - val_loss: 23.2828 - val_mae: 23.2828\n",
      "Epoch 943/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 23.0275 - mae: 23.0275 - val_loss: 23.1285 - val_mae: 23.1285\n",
      "Epoch 944/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 23.0341 - mae: 23.0341 - val_loss: 23.1619 - val_mae: 23.1619\n",
      "Epoch 945/1000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 22.9768 - mae: 22.9768 - val_loss: 23.1812 - val_mae: 23.1812\n",
      "Epoch 946/1000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 22.9890 - mae: 22.9890 - val_loss: 23.1562 - val_mae: 23.1562\n",
      "Epoch 947/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 22.9735 - mae: 22.9735 - val_loss: 23.1304 - val_mae: 23.1304\n",
      "Epoch 948/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 23.0475 - mae: 23.0475 - val_loss: 23.2550 - val_mae: 23.2550\n",
      "Epoch 949/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 23.0158 - mae: 23.0158 - val_loss: 23.3771 - val_mae: 23.3771\n",
      "Epoch 950/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 23.0682 - mae: 23.0682 - val_loss: 23.1278 - val_mae: 23.1278\n",
      "Epoch 951/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 23.0210 - mae: 23.0210 - val_loss: 23.1595 - val_mae: 23.1595\n",
      "Epoch 952/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 22.9745 - mae: 22.9745 - val_loss: 23.1637 - val_mae: 23.1637\n",
      "Epoch 953/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 22.9766 - mae: 22.9766 - val_loss: 23.1614 - val_mae: 23.1614\n",
      "Epoch 954/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 22.9752 - mae: 22.9752 - val_loss: 23.1433 - val_mae: 23.1433\n",
      "Epoch 955/1000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 22.9761 - mae: 22.9761 - val_loss: 23.1446 - val_mae: 23.1446\n",
      "Epoch 956/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 22.9744 - mae: 22.9744 - val_loss: 23.1622 - val_mae: 23.1622\n",
      "Epoch 957/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 22.9755 - mae: 22.9755 - val_loss: 23.1639 - val_mae: 23.1639\n",
      "Epoch 958/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 22.9764 - mae: 22.9764 - val_loss: 23.1585 - val_mae: 23.1585\n",
      "Epoch 959/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 22.9734 - mae: 22.9734 - val_loss: 23.1342 - val_mae: 23.1342\n",
      "Epoch 960/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 22.9848 - mae: 22.9848 - val_loss: 23.1623 - val_mae: 23.1623\n",
      "Epoch 961/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 22.9755 - mae: 22.9755 - val_loss: 23.1791 - val_mae: 23.1791\n",
      "Epoch 962/1000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 22.9869 - mae: 22.9869 - val_loss: 23.1476 - val_mae: 23.1476\n",
      "Epoch 963/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 22.9678 - mae: 22.9678 - val_loss: 23.1326 - val_mae: 23.1326\n",
      "Epoch 964/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 23.0899 - mae: 23.0899 - val_loss: 23.5332 - val_mae: 23.5332\n",
      "Epoch 965/1000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 23.1516 - mae: 23.1516 - val_loss: 23.1516 - val_mae: 23.1516\n",
      "Epoch 966/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 22.9695 - mae: 22.9695 - val_loss: 23.2593 - val_mae: 23.2593\n",
      "Epoch 967/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 23.2900 - mae: 23.2900 - val_loss: 23.4162 - val_mae: 23.4162\n",
      "Epoch 968/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 23.0856 - mae: 23.0856 - val_loss: 24.1203 - val_mae: 24.1203\n",
      "Epoch 969/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 23.5059 - mae: 23.5059 - val_loss: 24.4312 - val_mae: 24.4312\n",
      "Epoch 970/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 24.6986 - mae: 24.6986 - val_loss: 23.1637 - val_mae: 23.1637\n",
      "Epoch 971/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 23.1614 - mae: 23.1614 - val_loss: 26.2638 - val_mae: 26.2638\n",
      "Epoch 972/1000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 25.4771 - mae: 25.4771 - val_loss: 25.7294 - val_mae: 25.7294\n",
      "Epoch 973/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 26.1259 - mae: 26.1259 - val_loss: 25.3671 - val_mae: 25.3671\n",
      "Epoch 974/1000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 25.7154 - mae: 25.7154 - val_loss: 26.7626 - val_mae: 26.7626\n",
      "Epoch 975/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 26.0464 - mae: 26.0464 - val_loss: 23.2063 - val_mae: 23.2063\n",
      "Epoch 976/1000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 23.2082 - mae: 23.2082 - val_loss: 24.6463 - val_mae: 24.6463\n",
      "Epoch 977/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 24.9261 - mae: 24.9261 - val_loss: 23.5544 - val_mae: 23.5544\n",
      "Epoch 978/1000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 23.1599 - mae: 23.1599 - val_loss: 25.0872 - val_mae: 25.0872\n",
      "Epoch 979/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 24.2979 - mae: 24.2979 - val_loss: 25.6126 - val_mae: 25.6126\n",
      "Epoch 980/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 25.9996 - mae: 25.9996 - val_loss: 24.4218 - val_mae: 24.4218\n",
      "Epoch 981/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 24.6956 - mae: 24.6956 - val_loss: 28.6165 - val_mae: 28.6165\n",
      "Epoch 982/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 27.8456 - mae: 27.8456 - val_loss: 23.2725 - val_mae: 23.2725\n",
      "Epoch 983/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 23.3160 - mae: 23.3160 - val_loss: 24.5152 - val_mae: 24.5152\n",
      "Epoch 984/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 24.7956 - mae: 24.7956 - val_loss: 23.9719 - val_mae: 23.9719\n",
      "Epoch 985/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 23.3885 - mae: 23.3885 - val_loss: 24.7611 - val_mae: 24.7611\n",
      "Epoch 986/1000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 24.0288 - mae: 24.0288 - val_loss: 25.4661 - val_mae: 25.4661\n",
      "Epoch 987/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 25.8326 - mae: 25.8326 - val_loss: 24.3718 - val_mae: 24.3718\n",
      "Epoch 988/1000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 24.6500 - mae: 24.6500 - val_loss: 28.0549 - val_mae: 28.0549\n",
      "Epoch 989/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 27.2825 - mae: 27.2825 - val_loss: 23.1567 - val_mae: 23.1567\n",
      "Epoch 990/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 23.1000 - mae: 23.1000 - val_loss: 24.9242 - val_mae: 24.9242\n",
      "Epoch 991/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 25.2344 - mae: 25.2344 - val_loss: 23.2499 - val_mae: 23.2499\n",
      "Epoch 992/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 22.9951 - mae: 22.9951 - val_loss: 26.0177 - val_mae: 26.0177\n",
      "Epoch 993/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 25.1937 - mae: 25.1937 - val_loss: 26.1496 - val_mae: 26.1496\n",
      "Epoch 994/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 26.5770 - mae: 26.5770 - val_loss: 26.0704 - val_mae: 26.0704\n",
      "Epoch 995/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 26.4915 - mae: 26.4915 - val_loss: 24.8810 - val_mae: 24.8810\n",
      "Epoch 996/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 24.1319 - mae: 24.1319 - val_loss: 24.2449 - val_mae: 24.2449\n",
      "Epoch 997/1000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 23.6052 - mae: 23.6052 - val_loss: 25.2793 - val_mae: 25.2793\n",
      "Epoch 998/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 25.6272 - mae: 25.6272 - val_loss: 24.3419 - val_mae: 24.3419\n",
      "Epoch 999/1000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 24.6308 - mae: 24.6308 - val_loss: 27.4958 - val_mae: 27.4958\n",
      "Epoch 1000/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 26.7262 - mae: 26.7262 - val_loss: 23.1610 - val_mae: 23.1610\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 29.0675 - mae: 29.0675\n"
     ]
    }
   ],
   "source": [
    "gunnison_history, gunnison_model = run_deep_learning(gunnison, [100], learning_rate=0.01, epochs=1000, batch_size=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "42ce8f15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f75d44fceb0>]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(gunnison_history.history['loss'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebc1b2d3",
   "metadata": {},
   "source": [
    "## Display Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "de144264",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_loss(model_history, SKIP=10):\n",
    "    '''\n",
    "    Draws a graph of the loss, which is the distance between\n",
    "    the predicted and actual values during training and validation.\n",
    "    \n",
    "    Parameters: \n",
    "        model_history (tensorflow.history object): A models history after training.\n",
    "        SKIP (int): Amount of epochs to skip before graphing. 10 by default.\n",
    "    '''\n",
    "\n",
    "    for curr_history in model_history:\n",
    "        train_loss = curr_history['loss']\n",
    "        val_loss = curr_history['val_loss']\n",
    "\n",
    "        epochs = range(1, len(train_loss) + 1)\n",
    "\n",
    "        plt.plot(epochs[SKIP:], train_loss[SKIP:], 'g.', label='Training loss')\n",
    "        plt.plot(epochs[SKIP:], val_loss[SKIP:], 'b', label='Validation loss')\n",
    "        plt.title(f\"Activation Function: {curr_history['a_function']} \\n Arch: {curr_history['arch']}\\n Training and validation loss\")\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.legend()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42fa6335",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_accuracy(model_history, SKIP=10):\n",
    "    \n",
    "    '''\n",
    "    Draws a graph of the accuracy over the duration of training.\n",
    "    \n",
    "    Parameters: \n",
    "        model_history (tensorflow.history object): A models history after training.\n",
    "        SKIP (int): Amount of epochs to skip before graphing. 10 by default.\n",
    "    '''\n",
    "    \n",
    "    for curr_history in model_history:\n",
    "        plt.clf()\n",
    "\n",
    "        # Draw a graph of mean absolute error, which is another way of\n",
    "        # measuring the amount of error in the prediction.\n",
    "        train_mae = curr_history['accuracy']\n",
    "        val_mae = curr_history['val_accuracy']\n",
    "        \n",
    "        epochs = range(1, len(train_mae) + 1)\n",
    "\n",
    "        plt.plot(epochs[SKIP:], train_mae[SKIP:], 'g.', label='Training Accuracy')\n",
    "        plt.plot(epochs[SKIP:], val_mae[SKIP:], 'b.', label='Validation Accuracy')\n",
    "        plt.title(f\"Activation Function: {curr_history['a_function']} \\n Arch: {curr_history['arch']}\\n Training and validation accuracy\")\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.ylabel('ACC')\n",
    "        plt.legend()\n",
    "        plt.show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "48f8cb2c04e123a5f36026e83ef04ba8d8cb2e5b8983b92be00cf5b9b6813ba1"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
